{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f019bf7b-b572-422f-b32a-27ac7b30b6b8",
   "metadata": {},
   "source": [
    "### Definiciones DIGI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d7adcb-c307-4f65-981c-c8e46aece7fe",
   "metadata": {},
   "source": [
    "Data confectionare: Data en que conta descargo el fichero\n",
    "\n",
    "Data upload: debe ser la fecha en que se cargo el fichero a DB por financiero (en casi todos los casos deberia ser igual a data confectionare)\n",
    "\n",
    "Data cargo: Data real de devolución\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753e5fb7-6049-4611-9fa1-156b2948ac52",
   "metadata": {},
   "source": [
    "unpaid:\n",
    "\n",
    "    actual: base de deuda a dia de hoy, se sobreescribe todos los dias\n",
    "    detalle: deuda por factura, fecha carga = ultima fecha que fue deuda\n",
    "    historico: foto unpaid actual a dia 15 de mes, sin contar con la ultima facturacion. ejemplo: fecha carga 15/11, datos son deudas del dia 15/11 sin contar facturacion de octubre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea9c8ba-6b46-42db-aeb6-b998fd02b8bb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3a8dd-5a46-4176-bd6b-32fa807c49be",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a7ea79-bfef-4ee2-b756-1899caab4846",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d080ec81-b4ea-44c2-8d1a-0151b528ce32",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07964e81-a679-4fee-9363-094371b09cf8",
   "metadata": {},
   "source": [
    "# Python Trivia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2ed341-b81e-4b08-a8ee-908ee592d6f6",
   "metadata": {},
   "source": [
    "| Name | Description | age         \n",
    "| :- |-------------: | :-:\n",
    "|Mary| She is a nice girl.  | 20\n",
    "| Jackie Junior | He is a very young boy. | 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fea3844-456e-487e-a0ab-a18ec278bacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 code\n",
      "3 code\n",
      "4 code\n",
      "5 code\n"
     ]
    }
   ],
   "source": [
    "from inspect import currentframe, getframeinfo\n",
    "print(getframeinfo(currentframe()).lineno, \"code\")\n",
    "print(getframeinfo(currentframe()).lineno, \"code\")\n",
    "print(getframeinfo(currentframe()).lineno, \"code\")\n",
    "print(getframeinfo(currentframe()).lineno, \"code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0452bd-3251-4421-be71-b6b98f26366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.text import OffsetFrom\n",
    "import seaborn as sns\n",
    "\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c89cea-a292-4afe-b932-b73984ab6591",
   "metadata": {},
   "outputs": [],
   "source": [
    "devol_piloto = pd.read_csv('BBDD/LISTADO_DEVOLUCIONES_DEBITO_DIRECTO.csv', sep = ';', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9685a11c-ce5b-4ab7-994b-653541f7eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('C:/Users/adrian.fernandezb/Desktop/Documentos')\n",
    "import importlib\n",
    "import funciones\n",
    "importlib.reload(funciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc189a-e086-432b-a45b-50b78c8e016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ocultando las advertencias\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7156073-f1c6-4e6c-9a67-43e8fbccce2d",
   "metadata": {},
   "source": [
    "## Bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba53de0-4ea1-4626-97d7-4a8ead1dcc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En tu notebook\n",
    "import mi_modulo\n",
    "\n",
    "mi_modulo.mi_funcion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7533d96b-90ba-42a3-b7b6-dd2bf329f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummies\n",
    "\n",
    "for i in list(df['provincia'].unique()):\n",
    "    df[i]=np.where(df['provincia']==i,1,0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca0263e-e4d3-4f65-8c9a-31d8c263bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directorio diferente\n",
    "import sys\n",
    "sys.path.append('ruta/a/tu/modulo')\n",
    "\n",
    "import mi_modulo\n",
    "mi_modulo.mi_funcion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69aed09-b69e-4147-a00d-e9c891987092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para volver a cargar un modulo\n",
    "\n",
    "import importlib\n",
    "import tu_modulo\n",
    "\n",
    "importlib.reload(tu_modulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c80ad-74d2-49d6-aac4-5f1f752c922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(funciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed0700-a142-4d32-b574-3ddd4183c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file_list = os.listdir(carpeta_perfilado)\n",
    "perfilado_total = pd.DataFrame()\n",
    "for e in excel_file_list:\n",
    "    df = pd.read_excel(carpeta_perfilado+e)\n",
    "    df['Dia_fichero'] = e[28:30]\n",
    "    df['Año_fichero'] = e[22:26]\n",
    "    df['Mes_fichero'] = e[26:28]\n",
    "    perfilado_total = pd.concat([perfilado_total, df], axis = 0)\n",
    "\n",
    "perfilado_total.to_csv('V:/01_Scoring/16_PERFILADO/Perfilado Diario/Total_'+mes_perfilado2+'_2024.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b919136-76de-46b8-8a5f-e54e8d567e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cambiar un dato str de una columna\n",
    "\n",
    "df['columna'] = df['columna'].str.replace('palabra_mal_escrita', 'palabra_correcta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d3ad7a-68b4-4b59-aa9c-61dbd3da2212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos una muestra aleatoria de tamaño igual al ratio de cancelaciones\n",
    "\n",
    "clientes_muestra = clientes_filtrados.sample(frac=ratio_cancelaciones_scoring, random_state=1)    #Quitar el random_state si se quiere una muestra diferente cada vez que se corra el codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2500e345-79fa-4652-b564-cf2f890ca43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meses = {\n",
    "    1: ('01_ENERO_2024/', 'enero'),\n",
    "    2: ('02_FEBRERO_2024/', 'febrero'),\n",
    "    3: ('03_MARZO_2024/', 'marzo'),\n",
    "    4: ('04_ABRIL_2024/', 'abril'),\n",
    "    5: ('05_MAYO_2024/', 'mayo'),\n",
    "    6: ('06_JUNIO_2024/', 'junio'),\n",
    "    7: ('07_JULIO_2024/', 'julio'),\n",
    "    8: ('08_AGOSTO_2024/', 'agosto'),\n",
    "    11: ('11_NOVIEMBRE_2023/', 'noviembre'),\n",
    "    12: ('12_DICIEMBRE_2023/', 'diciembre')\n",
    "}\n",
    "\n",
    "try:\n",
    "    carpeta_perfilado, mes_perfilado2 = meses.get(mes_perfilado, (\"\", \"\"))\n",
    "    carpeta_perfilado = path0 + carpeta_perfilado\n",
    "except: print('Error de mes revisar!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3bbb9-6f61-452e-8045-2818c6080d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rellenando la data de variables categoricas con la moda\n",
    "for column in ['RANG_INGRESO','FLAG_LIMA_PROVINCIA']:\n",
    "    df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "\n",
    "#Rellenando la data de variables númericas con la media\n",
    "for column in ['EDAD','ANTIGUEDAD']:\n",
    "    df[column].fillna(round(df[column].mean()), inplace=True)\n",
    "\n",
    "del column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a66ced-bd22-4d96-a76d-ee6d12e628ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear lista a traves de input\n",
    "localidad_input = input(\"Localidades separados por coma: \")\n",
    "localidad_list = localidad_input.split(',')\n",
    "if len(localidad_list) > 1:\n",
    "    localidad = tuple(map(str, localidad_list))\n",
    "else:\n",
    "    localidad = str(localidad_list[0])\n",
    "filtros['localidad'] = localidad  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c81873-821d-4a46-beb2-d6bd4a3a9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "payments.iloc[24]\n",
    "\n",
    "\n",
    "# Nr.                                                                   25\n",
    "# ID Client                                                        8426123\n",
    "# Nume client                                                          NaN\n",
    "# Id bill                                                         60338671\n",
    "# Tip document                                              Ordin de plata\n",
    "# Nr. Ordin de plata / Chitanta                                624F2276252\n",
    "# Data                                                          01/01/2024\n",
    "# Valoare LEI                                                         60.0\n",
    "# Data inserarii                                                01/01/2024\n",
    "# User                                                            Software\n",
    "# Tip                                                             Postpaid\n",
    "# Banca                                                       La Caixa Web\n",
    "# Observatii                       Pago factura web LaCaixa, importe:60.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec3fdf5-0b7e-41a8-93bb-ad4e07875068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL ver valores unicos de una columna\n",
    "\n",
    "SELECT DISTINCT columna FROM tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c81e8e-c5a0-4882-b4b8-827951d30793",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = N'order_general'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1d4a14-1eeb-47d2-99ed-6c8a7e54a208",
   "metadata": {},
   "source": [
    "## Tratamiento decimales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0099463e-71de-4690-9ea1-b19b97b8bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cambiar a decimales españoles en un dato:\n",
    "\n",
    "a=1234.576  \n",
    "b=round(a,2)\n",
    "print(\"{:,}\".format(b).replace(',','~').replace('.',',').replace('~','.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2c94f-d4fb-4025-8a55-41cdfc5eb2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establecer division puntos y comas y formato en una columna:\n",
    "\n",
    "scoring2_canc_canal['estimacion_impago2'] = scoring2_canc_canal['estimacion_impago'].apply(lambda x: \"{:,.2f} €\".format(x))\n",
    "\n",
    "## Cambiar a decimales españoles en una columna:\n",
    "\n",
    "comas_por_puntos = [float(x.replace(',','.')) for x in bd_df['col_1']]\n",
    "\n",
    "## Cambiar a decimales españoles en una columna:\n",
    "\n",
    "for col in scoring2_canc_canal.columns:\n",
    "    scoring2_canc_canal[col] = scoring2_canc_canal[col].apply(lambda x: x.replace(',', '&').replace('.', ',').replace('&', '.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282272a0-9ee2-40a9-a8f1-02d1a405e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Abrir CSV con decimales españoles:\n",
    "\n",
    "bd_df = pd.read_csv(csv, sep=\";\", decimal=\",\")\n",
    "\n",
    "## Guardar CSV con el punto como separador decimal, con un número x de decimales float_format:\n",
    "\n",
    "bd_df.to_csv('out.csv', index=False, header=True,\n",
    "              decimal='.', sep=',', float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f69b5-538d-450e-a7aa-e6d1386b85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    data[col] = data[col].apply(lambda x: \"{:,.2f} %\".format(x))\n",
    "    data[col] = data[col].apply(lambda x: x.replace(',', '&').replace('.', ',').replace('&', '.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48c9df-aa2b-4d09-9784-94931d354626",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"{:,} €\".format(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb21ab-68b4-464e-bef7-405e2be5780b",
   "metadata": {},
   "source": [
    "## Graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb4860-41a6-4756-84a0-6bddc5b71e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximos = dev_totales_index[dev_totales_index['value'] > 8000].reset_index()\n",
    "for i in range(maximos.shape[1]+3):\n",
    "    if i == 0: plt.annotate(xy=(dev_totales_index['Data_Cargo'][1], maximos['value'][0]+60000), text=(' '+  maximos['Data_Cargo'][0].strftime('%d-%m-%Y')+ '\\n' +  (\"{:,} €\".format(maximos['value'][0]))))\n",
    "    elif i == 1: plt.annotate(xy=(dev_totales_index['Data_Cargo'][9], maximos['value'][i]+90000), text=('  '+ maximos['Data_Cargo'][i].strftime('%d-%m-%Y')+ '\\n' + (\"{:,} €\".format(maximos['value'][i]))))\n",
    "    elif i == 2: plt.annotate(xy=(dev_totales_index['Data_Cargo'][18], maximos['value'][i]+60000), text=(' '+ maximos['Data_Cargo'][i].strftime('%d-%m-%Y')+ '\\n' +  (\"{:,} €\".format(maximos['value'][i]))))\n",
    "    else: plt.annotate(xy=(maximos['Data_Cargo'][i], maximos['value'][i]), text=('  '+ maximos['Data_Cargo'][i].strftime('%d-%m-%Y')+ '\\n' +  (\"{:,} €\".format(maximos['value'][i]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e5f785-58ef-40b4-815a-5131ae047ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both the white and ticks styles can benefit from removing the top and right axes spines, which are not needed. The seaborn function despine() can be called to remove them\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc6c669-ad9d-4e0c-b4e4-b0d1f1e19712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico de barras apiladas 100%\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"colorblind\", n_colors=4).as_hex()[::-1] \n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "data[['Denegado_scoring','Deudor_antiguo','Deudor_temprano','Sin_impago']].plot(kind='bar', stacked=True, ax=ax, color=palette)\n",
    "plt.title('Deudores y denegados por fecha de solicitud')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c34aab-8bc8-4a94-bc95-27c8ac7f4fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar transparencia leyenda\n",
    "plt.legend(loc='upper center').get_frame().set_alpha(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345167f-f0d4-4c3a-a5bc-11bdc142a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar el formato del eje y a porcentaje\n",
    "import matplotlib.ticker as mtick\n",
    "fmt = '{x:,.0f}%'\n",
    "tick = mtick.StrMethodFormatter(fmt)\n",
    "ax.yaxis.set_major_formatter(tick)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f65df-5117-4ac3-bdd7-745a2e290d14",
   "metadata": {},
   "source": [
    "## Fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6dea76-467d-4b0f-ba2a-5de3fcd03ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_hoy = datetime.today().strftime('%d')\n",
    "mes_hoy = datetime.today().strftime('%m')\n",
    "año_hoy = datetime.today().strftime('%Y')\n",
    "semana_actual = datetime.today().isocalendar()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6272e49-ae91-4d74-9437-66a0280562ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir columna pandas\n",
    "\n",
    "devoluciones[\"Data_Cargo\"] = pd.to_datetime(devoluciones[\"Data_Cargo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29425615-0f9b-4fb1-a403-69c18f39ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "payments[\"Data\"] = pd.to_datetime(payments[\"Data\"], format='mixed', dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6393fce6-cf68-4ad6-a7fe-4fbb8b5be258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer mes, etc:\n",
    "\n",
    "dev_dia_mes['Mes_año'] = pd.DatetimeIndex(dev_dia_mes['Data_Cargo']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4848d5e8-b886-49bb-818e-8f1d2009a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dia de la semana\n",
    "\n",
    "dev_dia_mes['Dia_semana'] = dev_dia_mes['Data_Cargo'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a72ada-358e-45cc-8abb-45d9e503f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero de la semana:\n",
    "\n",
    "def custom_week(row):\n",
    "    date = pd.to_datetime(f\"{int(row['year_solicitud'])}-{int(row['mes_solicitud'])}-{int(row['dia_solicitud'])}\")\n",
    "    if (row['mes_solicitud'] == 1) and (row['dia_solicitud'] == 1):\n",
    "        return 1\n",
    "    else:\n",
    "        return date.isocalendar().week\n",
    "\n",
    "vali_obj['Semana_solicitud'] = vali_obj.apply(custom_week, axis=1)\n",
    "\n",
    "# Esto debido a que en 2023 el dia 1 fue de la ultima semana del 2022 y lo interpreta como 52 y no 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f3a94-0fc3-4f9c-a5d8-f3ecf586e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_past_date(str_days_ago):\n",
    "    TODAY = datetime.date.today()\n",
    "    splitted = str_days_ago.split()\n",
    "    if len(splitted) == 1 and splitted[0].lower() == 'today':\n",
    "        return str(TODAY.isoformat())\n",
    "    elif len(splitted) == 1 and splitted[0].lower() == 'yesterday':\n",
    "        date = TODAY - relativedelta(days=1)\n",
    "        return str(date.isoformat())\n",
    "    elif splitted[1].lower() in ['hour', 'hours', 'hr', 'hrs', 'h']:\n",
    "        date = datetime.datetime.now() - relativedelta(hours=int(splitted[0]))\n",
    "        return str(date.date().isoformat())\n",
    "    elif splitted[1].lower() in ['day', 'days', 'd']:\n",
    "        date = TODAY - relativedelta(days=int(splitted[0]))\n",
    "        return str(date.isoformat())\n",
    "    elif splitted[1].lower() in ['wk', 'wks', 'week', 'weeks', 'w']:\n",
    "        date = TODAY - relativedelta(weeks=int(splitted[0]))\n",
    "        return str(date.isoformat())\n",
    "    elif splitted[1].lower() in ['mon', 'mons', 'month', 'months', 'm']:\n",
    "        date = TODAY - relativedelta(months=int(splitted[0]))\n",
    "        return str(date.isoformat())\n",
    "    elif splitted[1].lower() in ['yrs', 'yr', 'years', 'year', 'y']:\n",
    "        date = TODAY - relativedelta(years=int(splitted[0]))\n",
    "        return str(date.isoformat())\n",
    "    else:\n",
    "        return \"Wrong Argument format\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ddfb9e-cff5-432c-8966-1bf35286d90a",
   "metadata": {},
   "source": [
    "## Agrupar dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5f87ff-f545-4398-bec7-23fe0987a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reestructuramos el dataframe\n",
    "devoluciones_melt = devoluciones.melt(id_vars='Data_Cargo', value_vars=['devoluciones_total', 'devoluciones_saldo'], var_name='Tipo', value_name='Importe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a957623-c927-4d02-b6c6-ed18876b83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"A\": \"a\", \"B\": \"c\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e65af41-bfb9-4ead-aafc-671ec8760be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pivot table:\n",
    "\n",
    "perfilado_2023.pivot_table(index='Mes_fichero', columns='Scoring_1_ACT', values='id_order', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746f939-f63d-4533-84c1-c03d9cf52a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Groupby complejo. La columna B apareceria dos veces, min y max, y para la C la suma:\n",
    "\n",
    "perfilado_2023.groupby('Mes_fichero').agg({'B': ['min', 'max'], 'C': 'sum'})\n",
    "\n",
    "## Otro groupby: en base a dos columnas, tipo para la base de impago !!\n",
    "\n",
    "unpaid_agrupado = unnn.groupby(['id_client', 'Fecha_carga']).agg({'Importe_total': 'sum', 'Importe_pagado': 'sum', 'Importe_pdte': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e4639-dc99-43fa-a94e-b771324edb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge:\n",
    "\n",
    "deuda_prod = pd.merge(deuda, productos, how='left', on='id_client2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5b7a5-4186-4e5b-8b3b-ae5ff5c48d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quitar duplicados:\n",
    "\n",
    "order_canal.drop_duplicates(subset='id_client2', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2319308-31aa-439d-92bd-72445fa91cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ordenar por indice\n",
    "\n",
    "orden_especifico = ['una_col', 'columna', 'acolumna', 'otra_columna']\n",
    "\n",
    "df_ordenado = df.reindex(orden_especifico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11566eb-c18a-48d0-bf6c-e873cc196623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumar la fila 1 y la fila 2\n",
    "df.loc['Suma'] = df.loc[1] + df.loc[2]\n",
    "\n",
    "# Eliminar las filas 1 y 2\n",
    "df = df.drop([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d547dbe-bb92-47d5-93f2-f9e00a72308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropna\n",
    "\n",
    "df.dropna(subset = ['name', 'toy'])\n",
    "df.drop(columns=['B', 'C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4617fdd0-2220-4aa4-91ce-e3a3b04ef63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar una columna que sume las filas\n",
    "df['Suma_Columnas'] = df.sum(axis=1)\n",
    "\n",
    "# Agregar una fila que sume las columnas\n",
    "df.loc['Suma_Filas'] = df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12fe51b-a582-4235-959d-102e40de2600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar\n",
    "\n",
    "pd.concat([s1, s2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589903f1-5aab-484f-aa11-1dc3add22ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos la función replace para corregir los errores\n",
    "\n",
    "df['columna'] = df['columna'].replace('ortografía incorrecta', 'ortografía correcta') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbccea8-34d5-4d99-812d-aef2cfcfee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = 'col1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4082547-b8a4-465a-b300-e163a02b774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que este es tu DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'col1': [True, False, np.nan],\n",
    "    'col2': [False, True, False],\n",
    "    'col3': [False, False, True],\n",
    "    'col4': ['a', 'b', 'c']\n",
    "})\n",
    "\n",
    "# Seleccionar solo las columnas booleanas\n",
    "df_bool = df.select_dtypes(include=[bool])\n",
    "\n",
    "# Reemplazar NaN o None con False\n",
    "df_bool.fillna(False, inplace=True)\n",
    "\n",
    "# Crear una nueva columna con el nombre de la columna donde es True\n",
    "df['nueva_columna'] = df_bool.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30676618-de1f-433e-a2d2-6e014fe4d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aliviar memoria quitando dataframes guardados\n",
    "\n",
    "import gc\n",
    "\n",
    "# Supongamos que 'df_pesado' es tu DataFrame original\n",
    "df_pesado = pd.DataFrame(...)\n",
    "\n",
    "# Creas una copia ligera de tu DataFrame\n",
    "df_ligero = df_pesado[['columna1', 'columna2', ...]]\n",
    "\n",
    "# Eliminas el DataFrame original\n",
    "del df_pesado\n",
    "\n",
    "# Llamas al recolector de basura de Python\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70e196-7e4f-482a-aeb0-d784a5fbf78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columna acumulados \n",
    "\n",
    "df['ventas_acumuladas'] = df['ventas_diarias'].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53cdd7f-c62d-412a-902a-78d2276b2b9e",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e84619-490c-4984-994b-58cfd0809121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mostramos el contenido de la tabla\n",
    "with pd.option_context('display.max_rows', 3, 'display.max_columns', None):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eedb82-9d26-45aa-8b5f-c60d413fd033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el número de trimestres\n",
    "trimestres = int(diferencia / pd.Timedelta('90 days'))\n",
    "print(trimestres)\n",
    "\n",
    "# Número de solicitudes por nacionalidad\n",
    "N_solicitudes = trimestres*125\n",
    "print(N_solicitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61415302-1ad9-4833-9edb-21d332bbe654",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eliminar duplicados en base a que esten validados y sino, por fecha validacion\n",
    "\n",
    "# Ordenamos por 'fecha_validacion'\n",
    "order_gral = order_gral.sort_values('fecha_validacion')\n",
    "\n",
    "# Creamos una nueva columna que será True si 'columna' es 'Validado' y False en caso contrario\n",
    "order_gral['es_validado'] = order_gral['OBSERVACION_FINAL'] == 'Validada'\n",
    "\n",
    "# Eliminamos los duplicados teniendo en cuenta la nueva columna 'es_validado'\n",
    "order_gral = order_gral.drop_duplicates(subset=['es_validado'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1623fb6-72e7-40cc-a049-caf0dbee1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para ver si hay valores repetidos \n",
    "\n",
    "(order_gral['id_client'].value_counts()>1).to_frame()['count'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec820669-f5bc-46c5-9dfa-3d33c23d9be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IDs para merge\n",
    "\n",
    "unpaid_actual['id_client']=unpaid_actual['id_client'].astype(str).str[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f224c8-ee82-4bce-a8bb-6789daecff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ver elementos duplicados\n",
    "\n",
    "conteo = unpaid_2['id_client'].value_counts()\n",
    "conteo_filtrado = conteo[conteo > 1]\n",
    "conteo_filtrado.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e04910-cb34-4e53-a024-a71576fb1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtro por valores nulos en una columna\n",
    "\n",
    "unpaid_2[unpaid_2['canal'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48beac-fda9-4502-9aea-65c71ed58a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encuentra el valor máximo en todo el DataFrame\n",
    "max_valor = df.values.max()\n",
    "\n",
    "# Encuentra la ubicación del valor máximo\n",
    "loc_max = np.where(df.values == max_valor)\n",
    "\n",
    "# Suma 10 al valor máximo\n",
    "df.iloc[loc_max[0][0], loc_max[1][0]] = max_valor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5aece-c3ab-475a-9cf4-5b217a81437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero de valores unicos en una columna, array, etc\n",
    "\n",
    "devoluciones_sep['motiv'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ae4c49-79c8-4f7c-870d-6ba006687c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porcentaje de cada valor en una columna\n",
    "\n",
    "base2['nacionalidad'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc82ada-2b15-4a4e-8edb-caf51e4cbbd8",
   "metadata": {},
   "source": [
    "df['Rango_Kilogramos'] = pd.cut(df['Kilogramos'], bins)\n",
    "\n",
    "La línea está utilizando la función pd.cut() de pandas para clasificar los valores en la columna ‘Kilogramos’ en diferentes intervalos o “bins”.\n",
    "\n",
    "La función pd.cut() toma como primer argumento la serie de datos que quieres clasificar, en este caso df['Kilogramos'], y como segundo argumento una lista de los límites de los intervalos, en este caso bins.\n",
    "\n",
    "El resultado es una nueva serie donde cada valor de ‘Kilogramos’ ha sido reemplazado por el intervalo al que pertenece. Esta nueva\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f01e3-cf79-44e3-a52d-d530530dd8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, -1, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f23e392-9ee0-4a74-84ec-c104a79ccea0",
   "metadata": {},
   "source": [
    "## Filtrado datos DIGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677ce21-cd56-4d05-8c33-bbcea7306458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con Numpy Select\n",
    "\n",
    "Conditions= [(Base_Fraude5['Movil_Postpago_ID']>=1) &(Base_Fraude5['Fibra_ID']>=1) & (Base_Fraude5['Fijo_ID']>=1),\n",
    "            (Base_Fraude5['Fibra_ID']>=1) & (Base_Fraude5['Fijo_ID']>=1),\n",
    "            (Base_Fraude5['Movil_Postpago_ID']>=1) &(Base_Fraude5['Fibra_ID']>=1),\n",
    "            (Base_Fraude5['Movil_Postpago_ID']>=1) &(Base_Fraude5['Fijo_ID']>=1),\n",
    "            (Base_Fraude5['Movil_Postpago_ID']>=1),\n",
    "            (Base_Fraude5['Fijo_ID']>=1),\n",
    "            (Base_Fraude5['Fibra_ID']>=1)]\n",
    "    \n",
    "values = ['01_Movil(Post)+Fibra+Fijo','09_Fibra+Fijo','04_Movil(Post)+Fibra','05_Movil(Post)+Fijo','06_Movil(Post)','15_Fijo','16_Fibra']\n",
    "\n",
    "Base_Fraude5['Tipificaciones_ID'] = np.select(Conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51706e89-ad93-417e-8201-7423b053ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Altas moviles\n",
    "\n",
    "def agrupar_altas(dataframe):\n",
    "    dataframe['altas'] = dataframe['alta_movil'].apply(\n",
    "        lambda x: 2 if x == 2 else\n",
    "        (3 if x == 3 else\n",
    "         (4 if x == 4 else \n",
    "          (5 if x == 5 else\n",
    "          (6 if x == 6 else\n",
    "           (1 if x == 1 else 0))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c358b7c1-57e0-4ea8-aa12-74b6e6b138ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tipos de paq\n",
    "\n",
    "def agrupar_connection(dataframe):\n",
    "    dataframe['Connection_Type'] = dataframe['TIPO_PAQ_FIBRA'].apply(\n",
    "        lambda x: 'Fibra_Neba' if x in ['Fibra 300Mb  y Prueba 6 meses','Fibra 100Mb','Fibra 30Mb y Prueba 6 meses','Fibra 50Mb','Fibra 1Gb', 'Fibra 300Mb','Fibra 500Mb','Fibra 30Mb'] else\n",
    "        ('Fibra_Pro' if x in ['Fibra PRO-DIGI 10 Gb','Fibra DIGI 300Mb', 'DIGI Fibra 500Mb','Fibra DIGI','DIGI Fibra 100Mb'] else\n",
    "         ('Fibra_Smart' if x in ['Fibra SMART 1Gb', 'Fibra SMART 500Mb'] else\n",
    "         ('Movil' if x == '0' else \n",
    "          ('Movil' if x == 0 else None)))))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f9ef13e-0a6a-4ed9-ac95-07ea57298500",
   "metadata": {},
   "source": [
    "# Actualizador canales\n",
    "\n",
    "def canales_act(x, y):\n",
    "    if z < 1:    \n",
    "        if x == 'STAND':\n",
    "            return '03_STAND'\n",
    "        elif x == 'TELEVENTA':\n",
    "            return '04_TELEVENTA'\n",
    "        elif x == 'D2D':\n",
    "            return '06_D2D'\n",
    "        elif x == 'C2C':\n",
    "            return '05_C2C'\n",
    "        elif x == 'DIGI STORE':\n",
    "            return '07_TIENDA_DIGI'\n",
    "        elif x == 'TELEVENTA':\n",
    "            return '04_TELEVENTA'\n",
    "        elif x == 'DEALER':\n",
    "            return '01_DC'\n",
    "        elif x == 'DEALER':\n",
    "            return '01_DC'\n",
    "        else:\n",
    "            return 'Error'\n",
    "    else:    \n",
    "        if x == 'Fibra_Neba' and y < 1:\n",
    "            return 'Alteba'\n",
    "        elif x in ['Fibra_Smart'] and y >= 1:\n",
    "            return 'PoSmart'\n",
    "        else:\n",
    "            return 'Error'\n",
    "\n",
    "perfilado_2023['Producto'] = perfilado_2023.apply(lambda row: agrupar(row['Connection_Type'], row['port_movil'], row['alta_movil']), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5845dd2f-80f1-44f0-9ad6-cc2ca0c5f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_general['canal'] = order_general['canal_venta'].apply(\n",
    "    lambda x: '01_DC' if x == 'DEALER' else\n",
    "    ('03_STAND' if x == 'STAND' else\n",
    "     ('04_TELEVENTA' if x == 'TELEVENTA' else\n",
    "     ('05_C2C' if x == 'C2C' else \n",
    "      ('06_D2D' if x == 'D2D' else \n",
    "      ('07_TIENDA_DIGI' if x == 'DIGI STORE' else \n",
    "       ('02_WEB' if x == 'WEB' else '00_Otros')))))))\n",
    "\n",
    "array(['DEALER', 'STAND', 'OFICINA', 'EMPRESAS', 'WEB', nan, 'D2D',\n",
    "       'TELEVENTA', 'C2C', 'EMISIONES', 'DIGI STORE'], dtype=object)\n",
    "\n",
    "array(['01_DC', '03_STAND', '02_WEB', '04_TELEVENTA', '05_C2C', '06_D2D',\n",
    "       '07_TIENDA_DIGI'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5731f4-b4f4-4348-a1a9-78ed54298995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualizador operadores donantes\n",
    "\n",
    "def agrupar_operador(dataframe):\n",
    "    dataframe['grupo_donante'] = dataframe['operador_donante'].apply(\n",
    "        lambda x: 'Movistar' if x in ['Telefonica Tech AIoT','Movistar YYY','TELEFÓNICA','MOVISTAR',\n",
    "                                      'TELEFÓNICA DE ESPAÑA, S.A.U', 'TELEFÃ?NICA DE ESPAÃ?A, S.A.U',\n",
    "                                      'Movistar XXXXX','Movistar XXXXXXXXXX', 'movistar', 'telefonica', 'telefónica', 'Telefónica',\n",
    "                                      'Movistar','11888 Servicio Consulta Telefonica S.A.','Movistar XXXXXXXXXX'] else\n",
    "        ('Orange' if x in ['Orange Business Spain','Orange','France Telecom España','France Telecom EspaÃ±a','ORANGE B4B TECHNOLOGY','Amena'] else\n",
    "         ('Vodafone' if x in ['Vodafone España','Vodafone ES','Vodafone','Vodafone EspaÃ±a S.A.U',\n",
    "                              'vodafone','Vodafone ONO','Vodafone España S.A.U',\n",
    "                              'Vodafone Roaming Services','Vodafone Es','ONO','Vodafone Enabler'] else \n",
    "          ('Pepephone' if x in ['PepePhone 3.0','PepePhone','Pepephone','pepephone'] else \n",
    "          ('MasMovil' if x in ['Virgin Telco', 'R Cable y Telecomunicaciones GALICIA S.A.', 'LCR Movil_ON movil','Happy móvil', 'IBERCOM', 'THE TELECOM BOUTIQUE',\n",
    "                               'Republica Movil','Mas Movil','MasMovil','Másmóvil','Xtra Telecom S.A.','Telecable Movil',\n",
    "                               'OPEN CABLE', 'Cable Móvil', 'FreedomPop/ Parlem', 'Euskaltel','Hits Mobile'] else \n",
    "          ('Alta' if x in ['0'] else \n",
    "           ('Lowi' if x in ['Lowi','Vodafone Enabler'] else \n",
    "          ('Jazztel' if x in ['Jazztel Móvil','Jazztel','Jazztel MÃ³vil'] else\n",
    "          ('Simyo' if x in ['Simyo'] else \n",
    "          ('Adamo' if x in ['Adamo'] else \n",
    "          ('Euskatel' if x in ['euskatel, Euskaltel S.A.', 'Euskaltel'] else \n",
    "          ('Yoigo' if x in ['Xfera Moviles S.A.','Yoigo', 'yoigo'] else 'Otros'))))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0762c414-f8d7-492a-af14-0dd2cd493dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar Scoring\n",
    "\n",
    "def asignar_scoring(dataframe):\n",
    "    def asignar_sco1(row):\n",
    "        if row['Decisión comercial'] == 'Permitir' and str(row['estado']) in ('Cancelled'):\n",
    "            return 'Cancelado_1'\n",
    "        elif row['Decisión comercial'] == 'Permitir' and str(row['estado']) in ('Validated'):\n",
    "            return 'No_cancelado_1'        \n",
    "        else:\n",
    "            return 'Revision_1'\n",
    "    def asignar_sco1_ACT(row):\n",
    "        if row['Decisión comercial'] == 'Permitir' and str(row['estado_actualizado']) in ('Cancelled'):\n",
    "            return 'Cancelado_1'\n",
    "        elif row['Decisión comercial'] == 'Permitir' and str(row['estado_actualizado']) in ('Validated'):\n",
    "            return 'No_cancelado_1'        \n",
    "        else:\n",
    "            return 'Revision_1' \n",
    "    def asignar_sco2(row):\n",
    "        if row['Decisión comercial'] == 'Permitir' and str(row['DECISION_SCORE']) == 'DENEGADO':\n",
    "            return 'Cancelado_2'\n",
    "        elif row['estado_actualizado']=='Cancelled' and str(row['Decisión comercial']) == 'Permitir' and row['DECISION_SCORE'] == 'REVISIÓN':\n",
    "            return 'Cancelado_2'\n",
    "        elif row['DECISION_SCORE']=='ACEPTADO' and str(row['Decisión comercial'])=='Permitir':\n",
    "            return 'No_cancelado_2' \n",
    "        elif row['DECISION_SCORE']=='REVISIÓN' and str(row['Decisión comercial'])=='Permitir' and row['estado_actualizado']=='Validated':\n",
    "            return 'No_cancelado_2' \n",
    "        else:\n",
    "            return 'Revision_2' \n",
    "    dataframe['Scoring_1_ANT'] = dataframe.apply(asignar_sco1, axis=1)\n",
    "    dataframe['Scoring_1_ACT'] = dataframe.apply(asignar_sco1_ACT, axis=1)\n",
    "    dataframe['Scoring_2'] = dataframe.apply(asignar_sco2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e938f-68b9-4979-a46d-fee2c9bb596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = unpaid_2.pivot_table(index='canal', columns='alta_movil', values='SUM(Importe_pdte)', aggfunc='sum')\n",
    "pivot_table.fillna(0, inplace=True)\n",
    "\n",
    "# pivot_table.loc['0_STAND_TIENDA'] = pivot_table.loc['03_STAND'] + pivot_table.loc['07_TIENDA_DIGI']\n",
    "# pivot_table = pivot_table.drop(['03_STAND'])\n",
    "\n",
    "orden_especifico = ['06_D2D','03_STAND','01_DC','04_TELEVENTA','05_C2C','02_WEB','00_Otros']\n",
    "pivot_table = pivot_table.reindex(orden_especifico)\n",
    "\n",
    "max_valor = pivot_table.values.max()\n",
    "loc_max = np.where(pivot_table.values == max_valor)\n",
    "pivot_table.iloc[loc_max[0][0], loc_max[1][0]] = max_valor + total_deuda - pivot_table.sum().sum()\n",
    "\n",
    "pivot_table['Total_canal'] = pivot_table.sum(axis=1)\n",
    "pivot_table.loc['Total_lineas'] = pivot_table.sum()\n",
    "\n",
    "pivot_table_deuda_real_canal = pivot_table.copy()\n",
    "\n",
    "pivot_table_deuda_real_canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7950d-1c57-4d38-83b5-d4cb6d516cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paquetes(entrada1,entrada2,entrada3):\n",
    "    if entrada1==0:\n",
    "        if entrada2==0:\n",
    "            if entrada3==0:\n",
    "                return '00_NADA'\n",
    "            else:\n",
    "                return '06_FIJO'\n",
    "        else:\n",
    "            if entrada3==0:\n",
    "                return '04_FIBRA'\n",
    "            else:\n",
    "                return '05_FIBRA+FIJO'\n",
    "    else:\n",
    "        if entrada2==0:\n",
    "            if entrada3==0:\n",
    "                return '01_MOVIL'\n",
    "            else:\n",
    "                return '07_MOV+FIJO'\n",
    "        else:\n",
    "            if entrada3==0:\n",
    "                return '02_MOV+FIBRA'\n",
    "            else:\n",
    "                return '03_MOV+FIJO+FIBRA'\n",
    "            \n",
    "vec=np.vectorize(paquetes)\n",
    "validaciones_filtrado['TIPO_PEDIDO'] = vec(validaciones_filtrado['paq_movil'], validaciones_filtrado['paq_fibra'],validaciones_filtrado['paq_fijo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c0677-a4d4-4f23-882d-da0d0b11bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_huella(portabilidad,alta_nueva,tipo_fibra):\n",
    "    if portabilidad==0 and alta_nueva>0 and (tipo_fibra=='NEO WIFI' or tipo_fibra=='Promo' or tipo_fibra=='0'):\n",
    "        return 'Alta_nueva'\n",
    "    elif portabilidad>0 and (tipo_fibra=='NEO WIFI' or tipo_fibra=='Promo' or tipo_fibra=='0'):\n",
    "        return 'Portabilidad'\n",
    "    elif portabilidad==0 and alta_nueva>0 and (tipo_fibra=='Fibra 1Gb' or tipo_fibra=='Fibra 300Mb' or tipo_fibra=='Fibra DIGI'):\n",
    "        return 'Alta_nueva_+_Neba'\n",
    "    elif portabilidad>0 and (tipo_fibra=='Fibra 1Gb' or tipo_fibra=='Fibra 300Mb' or tipo_fibra=='Fibra DIGI'):\n",
    "        return 'Portabilidad_+_Neba'\n",
    "    elif portabilidad==0 and alta_nueva>0 and (tipo_fibra=='Fibra PRO-DIGI 10 Gb' or tipo_fibra=='Fibra SMART 1Gb' or tipo_fibra=='Fibra SMART 500Mb'):\n",
    "        return 'Alta_nueva_+_Propia'\n",
    "    elif portabilidad>0 and (tipo_fibra=='Fibra PRO-DIGI 10 Gb' or tipo_fibra=='Fibra SMART 1Gb' or tipo_fibra=='Fibra SMART 500Mb'):\n",
    "        return 'Portabilidad_+_Propia'\n",
    "    elif portabilidad==0 and alta_nueva==0 and (tipo_fibra=='Fibra PRO-DIGI 10 Gb' or tipo_fibra=='Fibra SMART 1Gb' or tipo_fibra=='Fibra SMART 500Mb'):\n",
    "        return 'Propia'\n",
    "    elif portabilidad==0 and alta_nueva==0 and (tipo_fibra=='Fibra 1Gb' or tipo_fibra=='Fibra 300Mb' or tipo_fibra=='Fibra DIGI'):\n",
    "        return 'Neba'\n",
    "    else:\n",
    "        return 'Huella_por_determinar'\n",
    "    \n",
    "huella = lambda row: encontrar_huella(row['port_movil'],row['alta_movil'],row['TIPO_PAQ_FIBRA'])\n",
    "validaciones_filtrado['HUELLA_INTERMEDIO'] = validaciones_filtrado.apply(huella, axis=1)\n",
    "\n",
    "validaciones_filtrado['HUELLA']=validaciones_filtrado['TIPO_PEDIDO']+'_'+validaciones_filtrado['HUELLA_INTERMEDIO']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c2d7c1-d799-44f5-81b3-896da916cbe2",
   "metadata": {},
   "source": [
    "## Carpetas, explorador, excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444fd81-e02d-4dc1-a17b-15805665e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprobacion(archivo):\n",
    "    try:\n",
    "        def comprobar_tamaño(archivo):\n",
    "            tamaño = os.path.getsize(archivo)\n",
    "            if tamaño > 0:\n",
    "                print(\"El archivo final se ha encontrado y su tamaño es mayor que 0KB.\")\n",
    "            else: \n",
    "                print(\"Error, son 0KB.\")\n",
    "            input(\"Presiona cualquier tecla para cerrar el mensaje...\")\n",
    "        comprobar_tamaño(archivo)\n",
    "    except:\n",
    "        print(\"Error, no se ha guardado el archivo.\")\n",
    "        input(\"Presiona cualquier tecla para cerrar el mensaje...\")\n",
    "\n",
    "archivo = '//diginas/45_ANALISIS_DE_OPERACIONES/01_Scoring/14_detalle deuda diario/Detalle_deuda_'+hoy+'.xlsx'\n",
    "comprobacion(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d97001-de9f-40c9-846e-f52f01dc6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('devos_dias2.xlsx') as writer:\n",
    "    dev_totales_index.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "    devoluciones_saldo.to_excel(writer, index=False, sheet_name='Saldo_insf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14267e12-f847-4d3f-a9ad-337937e78c86",
   "metadata": {},
   "source": [
    "## Graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef30fe9-dfac-4c7d-b620-ecf1d2c7b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limitar numero de ticks\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f4aff-ed56-49e9-aa05-e280ec96d316",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fdc628-f42c-401c-a112-c38e0430ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nConfusion matrix:\\n', confusion_matrix(y_test, y_pred.iloc[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed7f9b-d7a9-4f85-8526-c4dfbffb9704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF: indica la existencia de multicolinealidad\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "  \n",
    "# creating dummies for gender \n",
    "data['Gender'] = data['Gender'].map({'Male':0, 'Female':1}) \n",
    "  \n",
    "# the independent variables set \n",
    "X = data[['Gender', 'Height', 'Weight']] \n",
    "  \n",
    "# VIF dataframe \n",
    "vif_data = pd.DataFrame() \n",
    "vif_data[\"feature\"] = X.columns \n",
    "  \n",
    "# calculating VIF for each feature \n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) \n",
    "                          for i in range(len(X.columns))] \n",
    "  \n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58e8eb8b-d43a-4e1d-83e2-29a5390a9045",
   "metadata": {},
   "source": [
    "Output :\n",
    "\n",
    "  feature        VIF\n",
    "0  Gender   2.028864\n",
    "1  Height  11.623103\n",
    "2  Weight  10.688377\n",
    "\n",
    "As we can see, height and weight have very high values of VIF, indicating that these two variables are highly correlated. This is expected as the height of a person does influence their weight. Hence, considering these two features together leads to a model with high multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2e408-ca3d-4d56-85f5-df65cdf49dcf",
   "metadata": {},
   "source": [
    "# ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779240d3-0f79-4170-a50f-ffc2de5f1008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_movil():\n",
    "    import pandas as pd\n",
    "    import numpy as np \n",
    "    from datetime import datetime, timedelta, date\n",
    "    from datetime import datetime,timedelta\n",
    "    import os, warnings, sys, IPython\n",
    "    username = os.getlogin()\n",
    "    warnings.filterwarnings('ignore')\n",
    "    # Conexión a la base de datos\n",
    "    cnx = conexionsoop(1)\n",
    "    cursor = cnx.cursor()\n",
    "    minutos, segundos = tiempo_restante()\n",
    "\n",
    "    consulta_base = \"SELECT id_order,DNI,nombre_cliente,id_client,telefono_contacto,id_dealer,provincia,direccion,email,cp,localidad,cuenta_bancaria,titular_cuenta,fecha_solicitud,fecha_validacion,canal,observaciones1,paq_pedido,paq_movil,paq_fibra,paq_fijo,port_movil,migr_movil,port_fijo,paq_celular,paq_datos,alta_movil,alta_fijo,TIPO_PAQ_FIBRA,nacionalidad,genero,fecha_nacimiento,OBSERVACION_FINAL FROM order_general\"\n",
    "\n",
    "    # Inicializa un DataFrame vacío para almacenar los resultados\n",
    "    df = pd.DataFrame()\n",
    "    filtro_excep = 'NO'\n",
    "    filtro_gest = 'nada'\n",
    "    filtro_exdeal = 'nada'\n",
    "    filtro_dominio = 'NO'\n",
    "    \n",
    "    filtro_extlf = 'nada'\n",
    "    filtro_exdni = 'nada'\n",
    "    filtro_excta = 'nada'\n",
    "    filtro_exdirec = 'nada'\n",
    "    filtro_extemail = 'nada'      \n",
    "    filtro_cotlf = 'nada'   \n",
    "    filtro_cocta = 'nada' \n",
    "    filtro_codni = 'nada' \n",
    "    filtro_codir = 'nada' \n",
    "    filtro_coemai = 'nada' \n",
    "    filtro_reglas = 'nada' \n",
    "    \n",
    "    # localidad, alta nueva\n",
    "\n",
    "    while True:\n",
    "        consulta = consulta_base\n",
    "        filtros = {}\n",
    "        filtros_fecha = {}\n",
    "        filtrosposte = {}\n",
    "        bancos = {\n",
    "            '2080': \"Abanca Corporación Bancaria\",'0061': \"Banca March\",'0188': \"Banco Alcalá\",'0182': \"Banco Bilbao Vizcaya Argentaria\",'0130': \"Banco Caixa Geral\",'0234': \"Banco Caminos\",\n",
    "            '2105': \"Banco Castilla-La Mancha\",'0240': \"Banco de Crédito Social Cooperativo\",'0081': \"Banco de Sabadell\",'0487': \"Banco Mare Nostrum\",'0186': \"Banco Mediolanum\",'0238': \"Banco Pastor\",\n",
    "            '0075': \"Banco Popular Español\",'0049': \"Banco Santander\",'3873': \"Banco Santander Totta\",'2038': \"Bankia\",'0128': \"Bankinter\",'0138': \"Bankoa\",'0152': \"Barclays Bank PLC\",\n",
    "            '3842': \"BNP Paribas Paris\",'3025': \"Caixa de Credit del Enginyers\",'2100': \"Caixabank\",'2045': \"Caja de Ahorros y Monte de Piedad de Ontinyent\",'3035': \"Caja Laboral Popular CC\",\n",
    "            '3081': \"Caja Rural Castilla-La Mancha\",'3058': \"Cajamar Caja Rural\",'2000': \"Cecabank\",'1474': \"Citibank Europe PLC\",'3821': \"Commerzbank AG\",'3877': \"Danske Bank A/S\",\n",
    "            '0019': \"Deutsche Bank SAE\",'0239': \"EVO Banco\",'2085': \"Ibercaja Banco\",'1465': \"ING Bank NV\",'2095': \"Kutxabank\",'2048': \"Liberbank\",'0131': \"Novo Banco\",'0073': \"Open Bank\",\n",
    "            '0108': \"Société Générale\",'2103': \"Unicaja Banco\",'0083':'RENTA 4','0216':'TARGOBANK','2013':'CATALUNYA BANC','0241':'A&G BANCA PRIVADA','0225':'Banco Cetelem'}\n",
    "\n",
    "        while True:\n",
    "            # Pregunta al usuario qué columna filtrar\n",
    "            columna_input = input(\"Campos de búsqueda antifraude (Canal/fecha_solicitud/alta_movil/port_movil/migr_movil/fecha portabilidad/operador receptor/fin): \")\n",
    "\n",
    "            if columna_input.lower() == 'fin':\n",
    "                break\n",
    "\n",
    "            # Crear filtros      \n",
    "\n",
    "                        \n",
    "            elif columna_input.lower() == 'id_order':\n",
    "                order_input = input(\"Orders separadas por coma: \")\n",
    "                order_list = order_input.split(',')\n",
    "                if len(order_list) > 1:\n",
    "                    id_order = tuple(map(int, order_list))\n",
    "                else:\n",
    "                    id_order = int(order_list[0])\n",
    "                filtros['id_order'] = id_order\n",
    "                \n",
    "            elif columna_input.lower() == 'canal':\n",
    "                canal_input = input(\"01_DC,03_STAND,02_WEB,04_TELEVENTA,05_C2C,06_D2D,07_TIENDA_DIGI\\nCanales separadas por coma: \")\n",
    "                canal_list = canal_input.split(',')\n",
    "                if len(canal_list) > 1:\n",
    "                    canal = tuple(map(str, canal_list))\n",
    "                else:\n",
    "                    canal = str(canal_list[0])\n",
    "                filtros['canal'] = canal\n",
    "                \n",
    "            elif columna_input.lower() == 'alta_movil':\n",
    "                localidad_input = input(\"Num separados por coma: \")\n",
    "                localidad_list = localidad_input.split(',')\n",
    "                if len(localidad_list) > 1:\n",
    "                    localidad = tuple(map(str, localidad_list))\n",
    "                else:\n",
    "                    localidad = str(localidad_list[0])\n",
    "                filtros['alta_movil'] = localidad     \n",
    "                \n",
    "\n",
    "            elif columna_input.lower() == 'migr_movil':\n",
    "                localidad_input = input(\"Num separados por coma: \")\n",
    "                localidad_list = localidad_input.split(',')\n",
    "                if len(localidad_list) > 1:\n",
    "                    localidad = tuple(map(str, localidad_list))\n",
    "                else:\n",
    "                    localidad = str(localidad_list[0])\n",
    "                filtros['migr_movil'] = localidad\n",
    "                \n",
    "            elif columna_input.lower() == 'port_movil':\n",
    "                localidad_input = input(\"Num separados por coma: \")\n",
    "                localidad_list = localidad_input.split(',')\n",
    "                if len(localidad_list) > 1:\n",
    "                    localidad = tuple(map(str, localidad_list))\n",
    "                else:\n",
    "                    localidad = str(localidad_list[0])\n",
    "                filtros['port_movil'] = localidad\n",
    "                print(getframeinfo(currentframe()).lineno, \"code\")\n",
    "\n",
    "            elif columna_input.lower() == 'paq_movil':\n",
    "                localidad_input = input(\"Num separados por coma: \")\n",
    "                localidad_list = localidad_input.split(',')\n",
    "                if len(localidad_list) > 1:\n",
    "                    localidad = tuple(map(str, localidad_list))\n",
    "                else:\n",
    "                    localidad = str(localidad_list[0])\n",
    "                filtros['paq_movil'] = localidad\n",
    "                \n",
    "            #####FECHA SOLICITUD\n",
    "            elif columna_input.lower() == 'fecha_solicitud' or columna_input.lower() == 'fecha solicitud':\n",
    "                fecha_input = input(\"Rango de fechas (formato: AAAA-MM-DD,AAAA-MM-DD): \")\n",
    "                fecha_inicio, fecha_fin = fecha_input.split(',')\n",
    "                filtros_fecha['fecha_solicitud'] = f\" BETWEEN '{fecha_inicio}' AND '{fecha_fin}'\"\n",
    "            \n",
    "    ##### ---- Posteriores -----\n",
    "            \n",
    "            elif columna_input.lower() == 'operador receptor':\n",
    "                oper = input(\"Operadores separados por coma: \")\n",
    "                oper = oper.split(',')\n",
    "                if len(oper) > 1:\n",
    "                    oper = list(map(str, oper))\n",
    "                else:\n",
    "                    oper = str(oper[0])\n",
    "                filtro_op = 'SI'                \n",
    "            elif columna_input.lower() == 'fecha portabilidad':\n",
    "                fechas_input = input(\"Rango de fechas (formato: AAAA-MM-DD,AAAA-MM-DD): \")\n",
    "                fechas = [fecha.strip() for fecha in fechas_input.split(',')]\n",
    "                filtrar_portabilidad = 'SI'\n",
    "\n",
    "            elif columna_input.lower() == 'Concentracion_telefono':\n",
    "                gest_i = input(\"Si/No: \")\n",
    "                if gest_i.lower() == 'si':\n",
    "                    filtro_cotlf = 'SI'\n",
    "                elif gest_i.lower() == 'no':\n",
    "                    filtro_cotlf = 'NO'\n",
    "                else:\n",
    "                    filtro_cotlf = 'nada'    \n",
    "\n",
    "            elif columna_input.lower() == 'concentracion_email':\n",
    "                gest_i = input(\"Si/No: \")\n",
    "                if gest_i.lower() == 'si':\n",
    "                    filtro_coemai = 'SI'\n",
    "                elif gest_i.lower() == 'no':\n",
    "                    filtro_coemai = 'NO'\n",
    "                else:\n",
    "                    filtro_coemai = 'nada'  \n",
    "                    \n",
    "            elif columna_input.lower() == 'reglas pandora':\n",
    "                reglas = input(\"Reglas disponibles: R88,R100,R81,R83,R82,R7,R6,R5,R22,R80,R1100,R4,R98,R101\\nPara fichero con y sin reglas: 'Todo'\\nReglas a filtrar: \")\n",
    "                filtro_reglas = 'SI'\n",
    "                reglas = reglas.split(',')\n",
    "                if len(reglas) > 1:\n",
    "                    reglas = tuple(map(str, reglas))\n",
    "                else:\n",
    "                    reglas = str(reglas[0])\n",
    "            \n",
    "            elif columna_input.lower() == 'concentracion_direccion':\n",
    "                gest_i = input(\"Si/No: \")\n",
    "                if gest_i.lower() == 'si':\n",
    "                    filtro_codir = 'SI'\n",
    "                elif gest_i.lower() == 'no':\n",
    "                    filtro_codir = 'NO'\n",
    "                else:\n",
    "                    filtro_codir = 'nada'    \n",
    "                \n",
    "            elif columna_input.lower() == 'concentracion_DNI':\n",
    "                gest_i = input(\"Si/No: \")\n",
    "                if gest_i.lower() == 'si':\n",
    "                    filtro_codni = 'SI'\n",
    "                elif gest_i.lower() == 'no':\n",
    "                    filtro_codni = 'NO'\n",
    "                else:\n",
    "                    filtro_codni = 'nada'    \n",
    "                \n",
    "            elif columna_input.lower() == 'concentracion_cuenta':\n",
    "                gest_i = input(\"Si/No: \")\n",
    "                if gest_i.lower() == 'si':\n",
    "                    filtro_cocta = 'SI'\n",
    "                elif gest_i.lower() == 'no':\n",
    "                    filtro_cocta = 'NO'\n",
    "                else:\n",
    "                    filtro_cocta = 'nada' \n",
    "\n",
    "        print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "       \n",
    "\n",
    "        if len(filtros)==0:\n",
    "            if len(filtros_fecha) ==0:\n",
    "                consulta += f\" WHERE paq_fibra < 1\"\n",
    "            else: \n",
    "                consulta += f\" WHERE paq_fibra < 1\"\n",
    "                consulta += f\" AND fecha_solicitud BETWEEN '{fecha_inicio}' AND '{fecha_fin}'\"\n",
    "                # consulta += f\" WHERE fecha_solicitud BETWEEN '{fecha_inicio}' AND '{fecha_fin}'\"\n",
    "        else:\n",
    "            if len(filtros_fecha) ==0:\n",
    "                consulta += \" WHERE \" + \" AND \".join([f\"{campo} IN {valor}\" if isinstance(valor, tuple) else f\"{campo} = '{valor}'\" for campo, valor in filtros.items()])\n",
    "            else:\n",
    "                consulta += \" WHERE \" + \" AND \".join([f\"{campo} IN {valor}\" if isinstance(valor, tuple) else f\"{campo} = '{valor}'\" for campo, valor in filtros.items()])\n",
    "                consulta += f\" AND paq_fibra < 1\"\n",
    "                consulta += f\" AND fecha_solicitud BETWEEN '{fecha_inicio}' AND '{fecha_fin}'\"\n",
    "       \n",
    "        consulta += f\" AND id_dealer NOT IN (10717390,7797899)\"  \n",
    "        \n",
    "        # Ejecuta la consulta y devuelve el resultado\n",
    "        minutos, segundos = tiempo_restante()\n",
    "        print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "        try:\n",
    "            try:\n",
    "                cursor.execute(consulta)  \n",
    "                resultado = cursor.fetchall()\n",
    "            except ConnectionResetError:\n",
    "                print('Se ha cortado la conexion con el servidor')\n",
    "            columnas = cursor.column_names\n",
    "            df_temp = pd.DataFrame(resultado, columns=columnas)\n",
    "            df = pd.concat([df, df_temp])\n",
    "\n",
    "        except: \n",
    "            print('La consulta no tiene ningun resultado') \n",
    "            print(consulta)\n",
    "\n",
    "             \n",
    "        del df_temp\n",
    "        correos = df['email'].tolist()\n",
    "        dominios_encontrados = []\n",
    "        for correo in correos:\n",
    "            try:\n",
    "                if correo and '@' in correo:\n",
    "                    indice = correo.find('@')\n",
    "                    dominio = correo[indice+1:correo.find('.', indice)]\n",
    "                    dominios_encontrados.append(dominio)\n",
    "                else:\n",
    "                    dominios_encontrados.append('error_dominio_no_encontrado')\n",
    "            except: dominios_encontrados.append('error_dominio_no_encontrado')\n",
    "            \n",
    "        df['dominio'] = dominios_encontrados\n",
    "        minutos, segundos = tiempo_restante()\n",
    "        print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "    \n",
    "\n",
    "        # nueva_consulta = input(\"¿Deseas añadir una nueva consulta? (s/n): \")\n",
    "        nueva_consulta = 'n'\n",
    "        if nueva_consulta.lower() != 's':\n",
    "            break\n",
    "\n",
    "    #Añadir resto de informacion\n",
    "\n",
    "    #Order estados:\n",
    "    seguir = True\n",
    "    orders_para_estados = list(df['id_order'])\n",
    "    minutos, segundos = tiempo_restante()\n",
    "    print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "\n",
    "    # df_list = []\n",
    "    # n = 4\n",
    "    # sublists = [orders_para_estados[i:i + n] for i in range(0, len(orders_para_estados), n)]\n",
    "    df_estados = pd.DataFrame()    \n",
    "    if len(orders_para_estados) == 1:\n",
    "        id_order = int(orders_para_estados[0])\n",
    "        consulta = f\"SELECT id_order,estado FROM order_estados WHERE id_order = {id_order}\"\n",
    "    else:\n",
    "        id_order = tuple(map(int, orders_para_estados))  \n",
    "        consulta = f\"SELECT id_order,estado FROM order_estados WHERE id_order IN {id_order}\"\n",
    "    try:\n",
    "        try:\n",
    "            cursor.execute(consulta)  \n",
    "            resultado = cursor.fetchall()\n",
    "        except ConnectionResetError:\n",
    "            print('Se ha cortado la conexion con el servidor')\n",
    "\n",
    "        columnas = cursor.column_names\n",
    "\n",
    "        # df_temp = pd.DataFrame(resultado, columns=columnas)\n",
    "        # df_list.append(df_temp)\n",
    "        # df_estados = pd.concat(df_temp)\n",
    "        df_estados = pd.DataFrame(resultado, columns=columnas)\n",
    "\n",
    "    except:        \n",
    "        print(\"···············  Consulta muy grande o sin resultados, introduzca nuevos filtros, porfavor  ···············\")\n",
    "        # return consulta\n",
    "\n",
    "    \n",
    "    df_estados['id_order'] = df_estados['id_order'].astype('int64')\n",
    "    df['id_order'] = df['id_order'].astype('int64')\n",
    "    df_2 = pd.merge(df, df_estados, how='left', on='id_order')\n",
    "\n",
    "\n",
    "    try: del df_estados\n",
    "    except: pass \n",
    "    try: del df\n",
    "    except: pass \n",
    "        \n",
    "    minutos, segundos = tiempo_restante()\n",
    "    print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "    # Añadir tipo_pedido\n",
    "    \n",
    "    def paquetes(entrada1,entrada2,entrada3):\n",
    "        if entrada1==0:\n",
    "            if entrada2==0:\n",
    "                if entrada3==0:\n",
    "                    return '00_NADA'\n",
    "                else:\n",
    "                    return '06_FIJO'\n",
    "            else:\n",
    "                if entrada3==0:\n",
    "                    return '04_FIBRA'\n",
    "                else:\n",
    "                    return '05_FIBRA+FIJO'\n",
    "        else:\n",
    "            if entrada2==0:\n",
    "                if entrada3==0:\n",
    "                    return '01_MOVIL'\n",
    "                else:\n",
    "                    return '07_MOV+FIJO'\n",
    "            else:\n",
    "                if entrada3==0:\n",
    "                    return '02_MOV+FIBRA'\n",
    "                else:\n",
    "                    return '03_MOV+FIJO+FIBRA'\n",
    "\n",
    "    minutos, segundos = tiempo_restante()\n",
    "    print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "                \n",
    "    vec=np.vectorize(paquetes)\n",
    "    df_2['tipo_pedido'] = vec(df_2['paq_movil'], df_2['paq_fibra'],df_2['paq_fijo'])\n",
    "    minutos, segundos = tiempo_restante()\n",
    "    print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "\n",
    "  \n",
    "    #Order paq:\n",
    "    if len(orders_para_estados) == 1:\n",
    "        id_order = int(orders_para_estados[0])\n",
    "        consulta = f\"SELECT id_order,telefono_pedido,nombre_paquete FROM orders_paquetes WHERE id_order = {id_order}\"\n",
    "    else:\n",
    "        id_order = tuple(map(int, orders_para_estados))  \n",
    "        consulta = f\"SELECT id_order,telefono_pedido,nombre_paquete FROM orders_paquetes WHERE id_order IN {id_order}\"\n",
    "    minutos, segundos = tiempo_restante()\n",
    "    print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            cursor.execute(consulta)  \n",
    "            resultado = cursor.fetchall()\n",
    "        except ConnectionResetError:\n",
    "            print('Se ha cortado la conexion con el servidor')\n",
    "        columnas = cursor.column_names\n",
    "        df_paq = pd.DataFrame(resultado, columns=columnas)\n",
    "    except:\n",
    "        seguir = False\n",
    "\n",
    "\n",
    "    if seguir == True:\n",
    "        df_paq['id_order'] = df_paq['id_order'].astype('int64')\n",
    "        df_2['id_order'] = df_2['id_order'].astype('int64')\n",
    "        df_3 = pd.merge(df_2, df_paq, how='left', on='id_order')\n",
    "\n",
    "        try: del df_2\n",
    "        except: pass \n",
    "        try: del df_paq\n",
    "        except: pass \n",
    "        \n",
    "        #Portabilidad:\n",
    "        elegir_metodo_cruce = 2   #Se guarda el codigo anterior ya que funcionaba para consultas pequeñas, pasamos a hacer el cruce en python para salvar lentitud servidor\n",
    "        if elegir_metodo_cruce == 1:\n",
    "            values = {\"telefono_pedido\": 0}\n",
    "            df_3.fillna(value=values, inplace=True)\n",
    "            tlf_para_estados = list(df_3['telefono_pedido'])\n",
    "            if len(tlf_para_estados) == 1:\n",
    "                tlfs = int(tlf_para_estados[0])            \n",
    "                consulta = f\"SELECT a.telefono,a.fecha_prevista_portout,a.operador_receptor,a.operador_donante FROM portabilidades_moviles_general a JOIN (SELECT telefono,MAX(fecha_prevista_portout) as fecha_maxima,operador_receptor,operador_donante FROM portabilidades_moviles_general WHERE telefono = {tlfs} AND estado = 'APOR' GROUP BY telefono) b ON a.telefono = b.telefono AND a.fecha_prevista_portout = b.fecha_maxima WHERE a.estado = 'APOR'\"\n",
    "            else:\n",
    "                tlfs = tuple(map(int, tlf_para_estados))  \n",
    "                consulta = f\"SELECT a.telefono,a.fecha_prevista_portout,a.operador_receptor,a.operador_donante FROM portabilidades_moviles_general a JOIN (SELECT telefono,MAX(fecha_prevista_portout) as fecha_maxima,operador_receptor,operador_donante FROM portabilidades_moviles_general WHERE telefono IN {tlfs} AND estado = 'APOR' GROUP BY telefono) b ON a.telefono = b.telefono AND a.fecha_prevista_portout = b.fecha_maxima WHERE a.estado = 'APOR'\"\n",
    "            try:\n",
    "                cursor.execute(consulta)  \n",
    "                resultado = cursor.fetchall()\n",
    "            except ConnectionResetError:\n",
    "                print('Se ha cortado la conexion con el servidor')\n",
    "            columnas = cursor.column_names\n",
    "            df_tlfs = pd.DataFrame(resultado, columns=columnas)\n",
    "\n",
    "        \n",
    "        elif elegir_metodo_cruce == 2:\n",
    "            values = {\"telefono_pedido\": 0}\n",
    "            df_3.fillna(value=values, inplace=True)\n",
    "            tlf_para_estados = list(df_3['telefono_pedido'])\n",
    "            if len(tlf_para_estados) == 1:\n",
    "                tlfs = int(tlf_para_estados[0])            \n",
    "                consulta = f\"SELECT telefono,fecha_prevista_portout,operador_donante,operador_receptor FROM portabilidades_moviles_general WHERE telefono = {tlfs} AND estado = 'APOR'\"\n",
    "            else:\n",
    "                tlfs = tuple(map(int, tlf_para_estados))  \n",
    "                consulta = f\"SELECT telefono,fecha_prevista_portout,operador_donante,operador_receptor FROM portabilidades_moviles_general WHERE telefono IN {tlfs} AND estado = 'APOR'\"\n",
    "            try:\n",
    "                cursor.execute(consulta)  \n",
    "                resultado = cursor.fetchall()\n",
    "            except ConnectionResetError:\n",
    "                print('Se ha cortado la conexion con el servidor')\n",
    "            columnas = cursor.column_names\n",
    "            resultado = cursor.fetchall()\n",
    "            df_tlfs = pd.DataFrame(resultado, columns=columnas)            \n",
    "            df_tlfs = df_tlfs.groupby('telefono').agg({'fecha_prevista_portout': 'max','operador_donante': 'first','operador_receptor': 'first'})\n",
    "            df_tlfs = df_tlfs.reset_index()\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "               \n",
    "        minutos, segundos = tiempo_restante()\n",
    "        print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "\n",
    "        df_tlfs['telefono'] = df_tlfs['telefono'].astype(str)\n",
    "        df_3['telefono_pedido'] = df_3['telefono_pedido'].astype(str) \n",
    "\n",
    "        if 'telefono' in df_tlfs.columns:\n",
    "            pass\n",
    "        else:\n",
    "            print('NO HAY TELEFONO')\n",
    "\n",
    "               \n",
    "        df_4 = pd.merge(df_3, df_tlfs, how='left', left_on='telefono_pedido', right_on='telefono')\n",
    "\n",
    "        print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "               \n",
    "\n",
    "\n",
    "        try: del df_3\n",
    "        except: pass \n",
    "        try: del df_tlfs\n",
    "        except: pass \n",
    "\n",
    "        if 'telefono' in df_4.columns:\n",
    "            pass\n",
    "        else:\n",
    "            print('NO HAY TELEFONO')\n",
    "            \n",
    "        df_4.drop_duplicates(subset='id_order', inplace=True)\n",
    "    \n",
    "        #Unpaid:\n",
    "        id_clients = tuple(df_4['id_client'].dropna().unique().astype(int))\n",
    "        minutos, segundos = tiempo_restante()\n",
    "        print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "    \n",
    "        if len(id_clients) == 1:\n",
    "            clients = int(id_clients[0])\n",
    "            consulta = f\"SELECT id_client,CUANTIA_TOTAL,FACTURAS_TOTAL FROM unpaid_actual WHERE id_client = {clients}\"\n",
    "            try:\n",
    "                cursor.execute(consulta)  \n",
    "                resultado = cursor.fetchall()\n",
    "            except ConnectionResetError:\n",
    "                print('Se ha cortado la conexion con el servidor')\n",
    " \n",
    "            columnas = cursor.column_names\n",
    "            df_unpaid = pd.DataFrame(resultado, columns=columnas)    \n",
    "            df_5 = pd.merge(df_4, df_unpaid, how='left', on='id_client')\n",
    "            df_5.drop_duplicates(subset='id_order', inplace=True)\n",
    "            df_5.rename(columns={'fecha_prevista_portout':'Fecha portabilidad', 'CUANTIA_TOTAL':'Deuda', 'FACTURAS_TOTAL':'Facturas impagadas','nombre_paquete':'Tarifa', 'telefono_pedido':'MSISDN', 'operador_receptor':'Operador receptor'}, inplace=True)\n",
    "            df_5['Deuda'].fillna(0,inplace=True)\n",
    "    \n",
    "        elif len(id_clients) == 0:\n",
    "            df_5 = df_4.copy()\n",
    "            df_5.rename(columns={'fecha_prevista_portout':'Fecha portabilidad', 'nombre_paquete':'Tarifa', 'telefono_pedido':'MSISDN', 'operador_receptor':'Operador receptor'}, inplace=True)\n",
    "            df_5['Deuda'] = 0\n",
    "        \n",
    "        else:\n",
    "            consulta = f\"SELECT id_client,CUANTIA_TOTAL,FACTURAS_TOTAL FROM unpaid_actual WHERE id_client IN {id_clients}\"\n",
    "            try:\n",
    "                cursor.execute(consulta)  \n",
    "                resultado = cursor.fetchall()\n",
    "            except ConnectionResetError:\n",
    "                print('Se ha cortado la conexion con el servidor')\n",
    "            columnas = cursor.column_names\n",
    "            df_unpaid = pd.DataFrame(resultado, columns=columnas)    \n",
    "            df_5 = pd.merge(df_4, df_unpaid, how='left', on='id_client')\n",
    "            df_5.drop_duplicates(subset='id_order', inplace=True)\n",
    "            df_5.rename(columns={'fecha_prevista_portout':'Fecha portabilidad', 'CUANTIA_TOTAL':'Deuda', 'FACTURAS_TOTAL':'Facturas impagadas', 'nombre_paquete':'Tarifa', 'telefono_pedido':'MSISDN', 'operador_receptor':'Operador receptor'}, inplace=True)\n",
    "            df_5['Deuda'].fillna(0,inplace=True)\n",
    "        minutos, segundos = tiempo_restante()\n",
    "        print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "        try: del df_4\n",
    "        except: pass \n",
    "        try: del df_unpaid\n",
    "        except: pass \n",
    "\n",
    "    \n",
    "        #Order ventas: usuario_venta:\n",
    "        if len(orders_para_estados) == 1:\n",
    "            id_order = int(orders_para_estados[0])\n",
    "            consulta = f\"SELECT id_order,usuario_venta FROM order_ventas WHERE id_order = {id_order}\"\n",
    "        else:\n",
    "            id_order = tuple(map(int, orders_para_estados))  \n",
    "            consulta = f\"SELECT id_order,usuario_venta FROM order_ventas WHERE id_order IN {id_order}\"\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(consulta)  \n",
    "            resultado = cursor.fetchall()\n",
    "        except ConnectionResetError:\n",
    "            print('Se ha cortado la conexion con el servidor')\n",
    "        columnas = cursor.column_names\n",
    "        df_vtas = pd.DataFrame(resultado, columns=columnas)\n",
    "        \n",
    "        df_vtas['id_order'] = df_vtas['id_order'].astype('int64')\n",
    "        df_5['id_order'] = df_5['id_order'].astype('int64')    \n",
    "        df_6 = pd.merge(df_5, df_vtas, how='left', on='id_order')\n",
    "        \n",
    "        if 'telefono' in df_6.columns:\n",
    "            pass\n",
    "        else:\n",
    "            print('NO HAY TELEFONO')\n",
    "            print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "        \n",
    "        #Gestion antifraude:\n",
    "        if len(orders_para_estados) == 1:\n",
    "            id_order = int(orders_para_estados[0])\n",
    "            consulta = f\"SELECT Order_ID, Tipologia FROM gest_fraude WHERE Order_ID = {id_order}\"\n",
    "        else:\n",
    "            id_order = tuple(map(int, orders_para_estados))  \n",
    "            consulta = f\"SELECT Order_ID, Tipologia FROM gest_fraude WHERE Order_ID IN {id_order}\"\n",
    "        \n",
    "\n",
    "        minutos, segundos = tiempo_restante()\n",
    "        print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "        try:\n",
    "            cursor.execute(consulta)  \n",
    "            resultado = cursor.fetchall()\n",
    "        except ConnectionResetError:\n",
    "            print('Se ha cortado la conexion con el servidor')\n",
    "        columnas = cursor.column_names\n",
    "        df_gest = pd.DataFrame(resultado, columns=columnas)   \n",
    "        df_gest['Order_ID'] = df_gest['Order_ID'].astype('int64')\n",
    "        df_6['id_order'] = df_6['id_order'].astype('int64')   \n",
    "        df_6 = pd.merge(df_6, df_gest, how='left', left_on='id_order', right_on='Order_ID')\n",
    "        df_6.drop(columns=['Order_ID'], inplace=True)\n",
    "        df_6.rename(columns={'Tipologia':'Gestionado'}, inplace=True) \n",
    "\n",
    "        df_6['Fecha portabilidad'] = pd.to_datetime(df_6['Fecha portabilidad'])\n",
    "        df_6['fecha_solicitud'] = pd.to_datetime(df_6['fecha_solicitud'])    \n",
    "        df_6['Tiempo en DIGI'] = (df_6['Fecha portabilidad'] - df_6['fecha_solicitud']).dt.days\n",
    "\n",
    "        df_6 = df_6[df_6['Tiempo en DIGI'] <= 20]\n",
    "        df_6 = df_6[df_6['Tiempo en DIGI'] >= 0]\n",
    "\n",
    "        if 'telefono' in df_6.columns:\n",
    "            pass\n",
    "        else:\n",
    "            print('NO HAY TELEFONO')\n",
    "        \n",
    "        \n",
    "        try: del df_gest\n",
    "        except: pass\n",
    "\n",
    "        \n",
    "        \n",
    "        #Excepciones antifraude:\n",
    "        \n",
    "            \n",
    "\n",
    "        if df_6.empty:\n",
    "            return('···························   Saltarina sin resultados   ···························')\n",
    "            \n",
    "        email_exc = list(df_6['direccion'])\n",
    "        if len(email_exc) == 1:\n",
    "            email_exc = str(email_exc[0])\n",
    "            consulta = f'SELECT direccion,observacion AS deny_direccion FROM blacklist_direccion WHERE direccion = \"{email_exc}\"'\n",
    "            \n",
    "            try:\n",
    "                cursor.execute(consulta)  \n",
    "                resultado = cursor.fetchall()\n",
    "            except ConnectionResetError:\n",
    "                print('Se ha cortado la conexion con el servidor')\n",
    "            resultado = cursor.fetchall()\n",
    "            columnas = cursor.column_names\n",
    "            df_excep = pd.DataFrame(resultado, columns=columnas)   \n",
    "            df_excep['direccion'] = df_excep['direccion'].astype('str')\n",
    "            df_6['direccion'] = df_6['direccion'].astype('str')    \n",
    "            df_6 = pd.merge(df_6, df_excep, how='left', on='direccion')\n",
    "            df_6.rename(columns={'deny_direccion':'Excepcion_direccion'}, inplace=True)\n",
    "\n",
    "\n",
    "        elif len(email_exc) == 0:\n",
    "\n",
    "            df_6['Excepcion_direccion'] = None\n",
    "        else:\n",
    "            email_exc_0 = []\n",
    "            for tlf in email_exc:\n",
    "                try:\n",
    "                    email_exc_0.append(str(tlf))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            del email_exc\n",
    "            email_exc_0 = tuple(email_exc_0)            \n",
    "            # tlfs_exc = tuple(map(int, tlfs_exc))  \n",
    "            consulta = f\"SELECT direccion,observacion AS deny_direccion FROM blacklist_direccion WHERE direccion IN {email_exc_0}\"\n",
    "            try:\n",
    "                cursor.execute(consulta)  \n",
    "                resultado = cursor.fetchall()\n",
    "            except ConnectionResetError:\n",
    "                print('Se ha cortado la conexion con el servidor')\n",
    "            columnas = cursor.column_names\n",
    "            df_excep = pd.DataFrame(resultado, columns=columnas)   \n",
    "            df_excep['direccion'] = df_excep['direccion'].astype('str')\n",
    "            df_6['direccion'] = df_6['direccion'].astype('str')    \n",
    "            df_6 = pd.merge(df_6, df_excep, how='left', on='direccion')\n",
    "            df_6.rename(columns={'deny_direccion':'Excepcion_direccion'}, inplace=True)\n",
    "\n",
    "\n",
    "        \n",
    "        try: del df_excep\n",
    "        except: pass\n",
    "\n",
    "        if 'telefono' in df_6.columns:\n",
    "            pass\n",
    "        else:\n",
    "            print('NO HAY TELEFONO')\n",
    "        \n",
    "        email_exc = list(df_6['email'])\n",
    "        \n",
    "        if len(email_exc) == 1:\n",
    "            email_exc = str(email_exc[0])\n",
    "            consulta = f\"SELECT email,observacion AS deny_email FROM blacklist_mail WHERE email = '{email_exc}'\"\n",
    "        else:\n",
    "            email_exc_0 = []\n",
    "            for tlf in email_exc:\n",
    "                try:\n",
    "                    email_exc_0.append(str(tlf))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            del email_exc\n",
    "            email_exc_0 = tuple(email_exc_0)            \n",
    "            # tlfs_exc = tuple(map(int, tlfs_exc))  \n",
    "            consulta = f\"SELECT email,observacion AS deny_email FROM blacklist_mail WHERE email IN {email_exc_0}\"\n",
    "       \n",
    "        try:\n",
    "            cursor.execute(consulta)  \n",
    "            resultado = cursor.fetchall()\n",
    "        except ConnectionResetError:\n",
    "            print('Se ha cortado la conexion con el servidor')\n",
    "        minutos, segundos = tiempo_restante()\n",
    "        print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "\n",
    "\n",
    "        columnas = cursor.column_names\n",
    "        df_excep = pd.DataFrame(resultado, columns=columnas)   \n",
    "\n",
    "        df_excep['email'] = df_excep['email'].astype('str')\n",
    "        df_6['email'] = df_6['email'].astype('str')    \n",
    "        df_6 = pd.merge(df_6, df_excep, how='left', on='email')\n",
    "        df_6.rename(columns={'deny_email':'Excepcion_email'}, inplace=True)\n",
    "        \n",
    "        try: del df_excep\n",
    "        except: pass\n",
    "            ###############\n",
    "        \n",
    "        tlfs_exc = list(df_6['telefono_contacto'])\n",
    "        \n",
    "        if len(tlfs_exc) == 1:\n",
    "            tlfs_exc = int(tlfs_exc[0])\n",
    "            consulta = f\"SELECT telefono,observacion AS deny_tlf FROM blacklist_telefono WHERE telefono = {tlfs_exc}\"\n",
    "            try:\n",
    "                cursor.execute(consulta)  \n",
    "                resultado = cursor.fetchall()\n",
    "            except ConnectionResetError:\n",
    "                print('Se ha cortado la conexion con el servidor')\n",
    "            columnas = cursor.column_names\n",
    "            df_excep = pd.DataFrame(resultado, columns=columnas)   \n",
    "    \n",
    "            df_excep['telefono'] = df_excep['telefono'].astype('str')\n",
    "            df_6['telefono_contacto'] = df_6['telefono_contacto'].astype('str')    \n",
    "            df_6 = pd.merge(df_6, df_excep, how='left', right_on='telefono', left_on='telefono_contacto')\n",
    "            try:\n",
    "                df_6.drop(columns='telefono', inplace=True)\n",
    "            except: pass\n",
    "            df_6.rename(columns={'deny_tlf':'Excepcion_telefono'}, inplace=True)\n",
    "        \n",
    "        elif len(tlfs_exc) == 0:\n",
    "            print('No hay telefonos de contacto')\n",
    "        else:\n",
    "            tlfs_exc_0 = []\n",
    "            for tlf in tlfs_exc:\n",
    "                try:\n",
    "                    tlfs_exc_0.append(int(tlf))\n",
    "                except ValueError:\n",
    "                    continue            \n",
    "            del tlfs_exc\n",
    "            tlfs_exc_0 = tuple(tlfs_exc_0)            \n",
    "            # tlfs_exc = tuple(map(int, tlfs_exc))  \n",
    "            consulta = f\"SELECT telefono,observacion AS deny_tlf FROM blacklist_telefono WHERE telefono IN {tlfs_exc_0}\"\n",
    "\n",
    "            try:\n",
    "                cursor.execute(consulta)  \n",
    "                resultado = cursor.fetchall()\n",
    "            except ConnectionResetError:\n",
    "                print('Se ha cortado la conexion con el servidor')\n",
    "            columnas = cursor.column_names\n",
    "            df_excep = pd.DataFrame(resultado, columns=columnas)   \n",
    "    \n",
    "            df_excep['telefono'] = df_excep['telefono'].astype('str')\n",
    "            df_6['telefono_contacto'] = df_6['telefono_contacto'].astype('str')    \n",
    "            df_6 = pd.merge(df_6, df_excep, how='left', right_on='telefono', left_on='telefono_contacto')\n",
    "            try:\n",
    "                df_6.drop(columns='telefono', inplace=True)\n",
    "            except: pass\n",
    "            df_6.rename(columns={'deny_tlf':'Excepcion_telefono'}, inplace=True)\n",
    "        \n",
    "        \n",
    "        try: del df_excep\n",
    "        except: pass\n",
    "            \n",
    "        ctas_exc = list(df_6['cuenta_bancaria'])\n",
    "        \n",
    "        if len(ctas_exc) == 1:\n",
    "            ctas_exc = str(ctas_exc[0])\n",
    "            consulta = f\"SELECT cuenta_bancaria,observacion AS deny_cta FROM blacklist_cuenta_bancaria WHERE cuenta_bancaria = {ctas_exc}\"\n",
    "        else:\n",
    "            ctas_exc = tuple(map(str, ctas_exc))  \n",
    "            consulta = f\"SELECT cuenta_bancaria,observacion AS deny_cta FROM blacklist_cuenta_bancaria WHERE cuenta_bancaria IN {ctas_exc}\"\n",
    "\n",
    "        try:\n",
    "            cursor.execute(consulta)  \n",
    "            resultado = cursor.fetchall()\n",
    "        except ConnectionResetError:\n",
    "            print('Se ha cortado la conexion con el servidor')\n",
    "        columnas = cursor.column_names\n",
    "        df_excep = pd.DataFrame(resultado, columns=columnas) \n",
    "        minutos, segundos = tiempo_restante()\n",
    "        print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "\n",
    "        df_excep['cuenta_bancaria'] = df_excep['cuenta_bancaria'].astype('str')\n",
    "        df_6['cuenta_bancaria'] = df_6['cuenta_bancaria'].astype('str')    \n",
    "        df_6 = pd.merge(df_6, df_excep, how='left', on='cuenta_bancaria')        \n",
    "        df_6.rename(columns={'deny_cta':'Excepcion_cuenta'}, inplace=True)\n",
    "        \n",
    "        try: del df_excep\n",
    "        except: pass\n",
    "        \n",
    "        DNI_exc = list(df_6['DNI'])\n",
    "\n",
    "        if len(DNI_exc) == 1:\n",
    "            DNI_exc = str(DNI_exc[0])\n",
    "            consulta = f\"SELECT dni,observacion AS deny_dni FROM blacklist_dni WHERE dni = '{DNI_exc}'\"\n",
    "        else:\n",
    "            DNI_exc = tuple(map(str, df_6['DNI']))  \n",
    "            consulta = f\"SELECT dni,observacion AS deny_dni FROM blacklist_dni WHERE dni IN {DNI_exc}\"\n",
    "\n",
    "        try:\n",
    "            cursor.execute(consulta)  \n",
    "            resultado = cursor.fetchall()\n",
    "        except ConnectionResetError:\n",
    "            print('Se ha cortado la conexion con el servidor')\n",
    "        columnas = cursor.column_names\n",
    "        df_excep = pd.DataFrame(resultado, columns=columnas)   \n",
    "        \n",
    "        df_excep['dni'] = df_excep['dni'].astype('str')\n",
    "        df_6['DNI'] = df_6['DNI'].astype('str')    \n",
    "        df_6 = pd.merge(df_6, df_excep, how='left', right_on='dni', left_on='DNI')\n",
    "        df_6.drop(columns='dni', inplace=True)\n",
    "        df_6.rename(columns={'deny_dni':'Excepcion_DNI'}, inplace=True)\n",
    "        \n",
    "        try: del df_excep\n",
    "        except: pass        \n",
    "\n",
    "        df_final = df_6.copy()\n",
    "        try:\n",
    "            del df_6,df_tlfs\n",
    "        except: pass\n",
    "\n",
    "        try:\n",
    "            del df_5,df_3\n",
    "        except: pass\n",
    "\n",
    "        try:\n",
    "            del df_vtas\n",
    "        except: pass\n",
    "        \n",
    "        try:\n",
    "            del df_gest,df_2\n",
    "        except: pass\n",
    "\n",
    "        try:\n",
    "            del df_unpaid\n",
    "        except: pass\n",
    "\n",
    "\n",
    "\n",
    "        # Cierra la conexión\n",
    "        cnx.close()\n",
    "        df_final.drop_duplicates(subset='id_order', inplace=True)\n",
    "    \n",
    "        try:\n",
    "            df_final.drop(['telefono'], axis=1, inplace=True)         \n",
    "        except: pass\n",
    "\n",
    "        try:\n",
    "            df_final.drop(['telefono_y'], axis=1, inplace=True)   \n",
    "            df_final.rename(columns={'telefono_x': 'telefono'}, inplace=True)\n",
    "        except: pass\n",
    "\n",
    "        try:\n",
    "            if app is None:\n",
    "                app = QtWidgets.QApplication(sys.argv)\n",
    "        except: pass\n",
    "        \n",
    "        #Filtros posteriores: \n",
    "            \n",
    "        \n",
    "        if filtro_gest == 'SI':\n",
    "            df_final = df_final[df_final['Gestionado'] != 'No gestionado']\n",
    "        elif filtro_gest == 'NO': \n",
    "            df_final = df_final[df_final['Gestionado'] == 'No gestionado']\n",
    "\n",
    "        if filtro_exdirec == 'SI':\n",
    "            df_final = df_final[~df_final['Excepcion_direccion'].isna()]\n",
    "        elif filtro_exdirec == 'NO': \n",
    "            df_final = df_final[df_final['Excepcion_direccion'].isna()]\n",
    "\n",
    "        if filtro_extemail == 'SI':\n",
    "            df_final = df_final[~df_final['Excepcion_email'].isna()]\n",
    "        elif filtro_extemail == 'NO': \n",
    "            df_final = df_final[df_final['Excepcion_email'].isna()]\n",
    "\n",
    "        if filtro_extlf == 'SI':\n",
    "            df_final = df_final[~df_final['Excepcion_telefono'].isna()]\n",
    "        elif filtro_extlf == 'NO': \n",
    "            df_final = df_final[df_final['Excepcion_telefono'].isna()]\n",
    "        \n",
    "        if filtro_exdni == 'SI':\n",
    "            df_final = df_final[~df_final['Excepcion_DNI'].isna()]\n",
    "        elif filtro_exdni == 'NO': \n",
    "            df_final = df_final[df_final['Excepcion_DNI'].isna()]\n",
    "\n",
    "        if filtro_excta == 'SI':\n",
    "            df_final = df_final[~df_final['Excepcion_cuenta'].isna()]\n",
    "        elif filtro_excta == 'NO': \n",
    "            df_final = df_final[df_final['Excepcion_cuenta'].isna()]   \n",
    "\n",
    "#### Agrupar columnas\n",
    "        df_final.rename(columns={\"Excepcion_cuenta\": \"Excepcion_cuenta (R100)\", \n",
    "                                 \"Excepcion_email\": \"Excepcion_email (R81)\",\n",
    "                                \"Excepcion_telefono\": \"Excepcion_telefono (R83)\",\n",
    "                                \"Excepcion_DNI\": \"Excepcion_DNI (R88)\",\n",
    "                                \"Excepcion_direccion\": \"Excepcion_direccion (R82)\"}, inplace=True)\n",
    "\n",
    "        unidades = ['G:', 'H:', 'W:', 'R:', 'V:', 'Y:', 'H:', 'A:', 'B:', 'C:', 'D:', 'E:', 'F:', 'I:', 'J:', 'K:', 'L:', 'M:', 'N:', 'O:', 'P:', 'Q:', 'S:', 'T:', 'U:', 'X:', 'Z:']\n",
    "\n",
    "        path0 = '/02_Antifraude/BBDD'\n",
    "        \n",
    "        for unidad in unidades:\n",
    "            path1 = unidad + path0\n",
    "            if os.path.exists(path1):\n",
    "                path = path1\n",
    "\n",
    "        del path1, path0, unidades, unidad\n",
    "\n",
    "        nrows = None\n",
    "            \n",
    "        R6 = pd.read_csv(path+'/R6.csv', nrows=nrows)\n",
    "        df_final['email'] = df_final['email'].astype('str')\n",
    "        R6['email'] = R6['email'].astype('str')    \n",
    "        R6.drop_duplicates(subset='email', inplace=True)\n",
    "        df_final = pd.merge(df_final, R6, how='left', on='email')\n",
    "        df_final.rename(columns={\"COUNT(DISTINCT DNI)\": \"Concentracion_email (R6)\"}, inplace=True)\n",
    "        del R6\n",
    "\n",
    "        R22 = pd.read_csv(path+'/R22.csv', nrows=nrows)\n",
    "        df_final['direccion'] = df_final['direccion'].astype('str')\n",
    "        R22['direccion'] = R22['direccion'].astype('str')    \n",
    "        R22.drop_duplicates(subset='direccion', inplace=True)\n",
    "        df_final = pd.merge(df_final, R22, how='left', on='direccion')\n",
    "        df_final.rename(columns={\"COUNT(DISTINCT DNI)\": \"Concentracion_direccion (R22)\"}, inplace=True)\n",
    "        del R22\n",
    "        \n",
    "        R5 = pd.read_csv(path+'/R5.csv', nrows=nrows)\n",
    "        df_final['telefono_contacto'] = df_final['telefono_contacto'].astype('str')\n",
    "        R5['telefono_contacto'] = R5['telefono_contacto'].astype('str')  \n",
    "        R5.drop_duplicates(subset='telefono_contacto', inplace=True)\n",
    "        df_final = pd.merge(df_final, R5, how='left', on='telefono_contacto')\n",
    "        df_final.rename(columns={\"count\": \"Concentracion_telefono (R5)\"}, inplace=True)\n",
    "        del R5\n",
    "\n",
    "        R55 = pd.read_csv(path+'/R55.csv', nrows=nrows)\n",
    "        df_final['DNI'] = df_final['DNI'].astype('str')\n",
    "        R55['DNI'] = R55['DNI'].astype('str') \n",
    "        R55.drop_duplicates(subset='DNI', inplace=True)\n",
    "        R55.rename(columns={\"count\": \"Concentracion_solicitud (R55)\"}, inplace=True)\n",
    "        df_final = pd.merge(df_final, R55, how='left', on='DNI')\n",
    "        del R55\n",
    "\n",
    "        R7 = pd.read_csv(path+'/R7.csv', nrows=nrows)\n",
    "        df_final['cuenta_bancaria'] = df_final['cuenta_bancaria'].astype('str')\n",
    "        R7['cuenta_bancaria'] = R7['cuenta_bancaria'].astype('str')    \n",
    "        R7.drop_duplicates(subset='cuenta_bancaria', inplace=True)\n",
    "        df_final = pd.merge(df_final, R7, how='left', on='cuenta_bancaria')\n",
    "        df_final.rename(columns={\"COUNT(DISTINCT DNI)\": \"Concentracion_cuenta (R7)\"}, inplace=True)\n",
    "        del R7\n",
    "\n",
    "\n",
    "        R80 = pd.read_csv(path+'/R80.csv', sep = ';', nrows=nrows)\n",
    "        df_final['id_dealer'] = df_final['id_dealer'].astype('str')\n",
    "        R80['id_dealer'] = R80['id_dealer'].astype('str')\n",
    "        R80.drop_duplicates(subset='id_dealer', inplace=True)\n",
    "        df_final = pd.merge(df_final, R80, how='left', on='id_dealer')\n",
    "        df_final.rename(columns={\"observacion_dealer\": \"Excepcion_dealer (R80)\"}, inplace=True)\n",
    "        del R80  \n",
    "\n",
    "        R1100 = pd.read_csv(path+'/R1100.csv', nrows=nrows)\n",
    "        R1100.rename(columns={\"id_client\": \"Impago_cta_bancaria (R1100)\"}, inplace=True)\n",
    "        R1100.drop_duplicates(subset='cuenta_bancaria', inplace=True)\n",
    "        df_final['cuenta_bancaria'] = df_final['cuenta_bancaria'].astype('str')\n",
    "        R1100['cuenta_bancaria'] = R1100['cuenta_bancaria'].astype('str')\n",
    "        df_final = pd.merge(df_final, R1100, how='left', on='cuenta_bancaria')\n",
    "        del R1100   \n",
    "\n",
    "        df_final['Impago_cta_bancaria (R1100)'] = df_final['Impago_cta_bancaria (R1100)'].apply(lambda x: 'Si' if pd.notnull(x) else x)\n",
    "        \n",
    "\n",
    "        if filtro_cotlf == 'SI':\n",
    "            df_final = df_final[~df_final['Concentracion_telefono (R5)'].isna()]\n",
    "        elif filtro_cotlf == 'NO': \n",
    "            df_final = df_final[df_final['Concentracion_telefono (R5)'].isna()] \n",
    "            \n",
    "        if filtro_cocta == 'SI':\n",
    "            df_final = df_final[~df_final['Concentracion_cuenta (R7)'].isna()]\n",
    "        elif filtro_cocta == 'NO': \n",
    "            df_final = df_final[df_final['Concentracion_cuenta (R7)'].isna()]  \n",
    "\n",
    "        if filtro_exdeal == 'SI':\n",
    "            df_final = df_final[~df_final['Excepcion_dealer (R80)'].isna()]\n",
    "        elif filtro_exdeal == 'NO': \n",
    "            df_final = df_final[df_final['Excepcion_dealer (R80)'].isna()] \n",
    "            \n",
    "        if filtro_codir == 'SI':\n",
    "            df_final = df_final[~df_final['Concentracion_direccion (R22)'].isna()]\n",
    "        elif filtro_codir == 'NO': \n",
    "            df_final = df_final[df_final['Concentracion_direccion (R22)'].isna()] \n",
    "\n",
    "        if filtro_coemai == 'SI':\n",
    "            df_final = df_final[~df_final['Concentracion_email (R6)'].isna()]\n",
    "        elif filtro_coemai == 'NO': \n",
    "            df_final = df_final[df_final['Concentracion_email (R6)'].isna()] \n",
    "\n",
    "        def get_codes(row):\n",
    "            codes = []\n",
    "            if pd.notnull(row['Excepcion_cuenta (R100)']): codes.append('R100')\n",
    "            if pd.notnull(row['Excepcion_email (R81)']): codes.append('R81')\n",
    "            if pd.notnull(row['Excepcion_telefono (R83)']): codes.append('R83')\n",
    "            if pd.notnull(row['Excepcion_DNI (R88)']): codes.append('R88')\n",
    "            if pd.notnull(row['Excepcion_direccion (R82)']): codes.append('R82')\n",
    "            if pd.notnull(row['Excepcion_dealer (R80)']): codes.append('R80')\n",
    "            if pd.notnull(row['Concentracion_email (R6)']): codes.append('R6 (' + \"{:,.0f}\".format(row['Concentracion_email (R6)']).replace(',', '&').replace('.', ',').replace('&', '.') + ')')\n",
    "            if pd.notnull(row['Concentracion_direccion (R22)']): codes.append('R22 (' + \"{:,.0f}\".format(row['Concentracion_direccion (R22)']).replace(',', '&').replace('.', ',').replace('&', '.') + ')')\n",
    "            if pd.notnull(row['Concentracion_cuenta (R7)']): codes.append('R7 (' + \"{:,.0f}\".format(row['Concentracion_cuenta (R7)']).replace(',', '&').replace('.', ',').replace('&', '.') + ')')\n",
    "            if pd.notnull(row['Concentracion_telefono (R5)']): codes.append('R5 (' + \"{:,.0f}\".format(row['Concentracion_telefono (R5)']).replace(',', '&').replace('.', ',').replace('&', '.') + ')')\n",
    "            if pd.notnull(row['Impago_cta_bancaria (R1100)']): codes.append('R1100')\n",
    "            if pd.notnull(row['Concentracion_solicitud (R55)']): codes.append('R55 (' + \"{:,.0f}\".format(row['Concentracion_solicitud (R55)']).replace(',', '&').replace('.', ',').replace('&', '.') + ')')\n",
    "\n",
    "            return ', '.join(codes)\n",
    "\n",
    "        df_final['Code_Excepciones'] = df_final.apply(get_codes, axis=1) \n",
    "        df_final['Gestionado'].fillna('No gestionado', inplace=True)\n",
    "\n",
    "        motivos = pd.read_csv('//diginas/45_ANALISIS_DE_OPERACIONES/02_Antifraude/BBDD/LISTADO_DEVOLUCIONES_DEBITO_DIRECTO.csv', sep='|', on_bad_lines='skip')\n",
    "        motivos = motivos[motivos['motiv'].isin(['Cuenta cancelada.','Cuenta bloqueada y o cuenta bloqueada por el deudor para adeudos directos.'])][['id_client']]\n",
    "        motivos['R101'] = 'R101'\n",
    "        motivos['id_client'] = motivos['id_client'].astype('str')\n",
    "        df_final['id_client'] = df_final['id_client'].astype('str').str[:-2]\n",
    "        df_final = pd.merge(df_final, motivos, how='left', on='id_client')\n",
    "        \n",
    "        def get_codes2(row):\n",
    "            codes = row['Code_Excepciones']\n",
    "            if ('R' in row['Code_Excepciones']) and (row['Deuda']>1): codes += ', R4'\n",
    "            if isinstance(row['R101'], str) and ('R' in row['R101']) and (row['Deuda']>1):\n",
    "                if len(row['Code_Excepciones']) < 3:\n",
    "                    codes += 'R101'   \n",
    "                else:\n",
    "                    codes += ', R101' \n",
    "            if row['Gestionado'] != 'No gestionado': \n",
    "                if len(row['Code_Excepciones']) < 3:\n",
    "                    codes += 'R98'   \n",
    "                else:\n",
    "                    codes += ', R98'            \n",
    "            return codes\n",
    "\n",
    "        \n",
    "        df_final['Code_Excepciones'] = df_final.apply(get_codes2, axis=1)  \n",
    "\n",
    "        minutos, segundos = tiempo_restante()\n",
    "        print(getframeinfo(currentframe()).lineno, \"code  -  \", minutos, \"min\",segundos,\"s\")\n",
    "        \n",
    "        \n",
    "        df_final.rename(columns={'operador_donante':'Operador donante'}, inplace=True)\n",
    "        \n",
    "        df_final['Deuda'] = df_final['Deuda'].apply(lambda x: \"{:,.2f} €\".format(x))\n",
    "        df_final['Deuda'] = df_final['Deuda'].apply(lambda x: x.replace(',', '&').replace('.', ',').replace('&', '.'))\n",
    "        df_final.drop(columns=['Excepcion_cuenta (R100)', 'Excepcion_telefono (R83)',\n",
    "                               'Excepcion_email (R81)', 'Concentracion_solicitud (R55)',\n",
    "                               'Excepcion_direccion (R82)', 'Excepcion_DNI (R88)', \n",
    "                               'Excepcion_dealer (R80)', 'R101',\n",
    "                               'Concentracion_direccion (R22)', 'Concentracion_email (R6)', \n",
    "                               'Impago_cta_bancaria (R1100)', 'Concentracion_telefono (R5)', 'Concentracion_cuenta (R7)'], inplace=True)\n",
    "\n",
    "        df_final.rename(columns={'Code_Excepciones':'Reglas Pandora'}, inplace=True)\n",
    "        col = df_final.pop('Reglas Pandora')\n",
    "        df_final.insert(4, col.name, col)\n",
    "        \n",
    "\n",
    "        df_final = df_final[df_final['Reglas Pandora'].str.contains('R', na=False)]\n",
    "\n",
    "\n",
    "        if filtro_reglas == 'SI':\n",
    "            if type(reglas) is str:\n",
    "                if reglas.lower() == 'todo':\n",
    "                    pass\n",
    "                else:\n",
    "                    df_final = df_final[df_final['Reglas Pandora'].str.contains(reglas.upper(), na=False)]       \n",
    "            else:\n",
    "                df_final = df_final[df_final['Reglas Pandora'].str.contains('|'.join(reglas).upper(), na=False)] \n",
    "            if df_final.shape[0] < 1:\n",
    "                print('···························   Sin registros   ···························\\n')\n",
    "            else: pass\n",
    "        else: df_final = df_final[df_final['Reglas Pandora'].str.contains('R', na=False)] \n",
    "            \n",
    "        df_final['dominio'] = df_final['dominio'].str.lower()\n",
    "        df_final = df_final[~df_final['nombre_cliente'].str.contains('TEST|test|Test', na=False)]\n",
    "\n",
    "        df_final = df_final[df_final['DNI'] != '11111111H']\n",
    "\n",
    "        df_final.drop_duplicates(subset='id_order', inplace=True)\n",
    "\n",
    "        try:\n",
    "            df_final.drop(columns=['Gestionado'], inplace=True)\n",
    "        except: pass\n",
    "\n",
    "        if df_final.shape[0] < 1:\n",
    "            print('···························   Sin registros   ···························\\n')\n",
    "        else: pass\n",
    "            \n",
    "        print('···························   Saltarina completada   ···························\\n')\n",
    "      \n",
    " \n",
    "        input_final = input(\"Previsualizar/Guardar: \")\n",
    "        input_final = str(input_final).lower()\n",
    "        hoy = datetime.today().strftime('%Y-%m-%d')\n",
    "        if input_final == 'previsualizar':\n",
    "            print('\\nPrevisualización 6 filas:\\n')\n",
    "            with pd.option_context('display.max_rows', 7, 'display.max_columns', None):\n",
    "                display(df_final)\n",
    "            input_final = input(\"Guardar finalmente (si/no): \")\n",
    "            input_final = str(input_final).lower()\n",
    "            if input_final == 'si':\n",
    "                try:\n",
    "                    guardar_excel(df_final, username +'/Saltarina '+hoy+' ('+username+')')       \n",
    "                except: \n",
    "                    for unidad in ['G:', 'H:', 'W:', 'R:', 'V:', 'Y:', 'H:', 'A:', 'B:', 'C:', 'D:', 'E:', 'F:', 'I:', 'J:', 'K:', 'L:', 'M:', 'N:', 'O:', 'P:', 'Q:', 'S:', 'T:', 'U:', 'X:', 'Z:']: \n",
    "                        if os.path.exists(unidad + '/02_Antifraude/04_PYTHON/Base de datos analisis'):\n",
    "                            os.makedirs(unidad + '/02_Antifraude/04_PYTHON/Base de datos analisis/'+username)\n",
    "                    guardar_excel(df_final, username +'/Saltarina '+hoy+' ('+username+')') \n",
    "        elif input_final == 'guardar':\n",
    "            try:\n",
    "                guardar_excel(df_final, username +'/Saltarina '+hoy+' ('+username+')')    \n",
    "            except: \n",
    "                for unidad in ['G:', 'H:', 'W:', 'R:', 'V:', 'Y:', 'H:', 'A:', 'B:', 'C:', 'D:', 'E:', 'F:', 'I:', 'J:', 'K:', 'L:', 'M:', 'N:', 'O:', 'P:', 'Q:', 'S:', 'T:', 'U:', 'X:', 'Z:']: \n",
    "                    if os.path.exists(unidad + '/02_Antifraude/04_PYTHON/Base de datos analisis'):\n",
    "                        os.makedirs(unidad + '/02_Antifraude/04_PYTHON/Base de datos analisis/'+username)\n",
    "                guardar_excel(df_final, username +'/Saltarina '+hoy+' ('+username+')')  \n",
    "                \n",
    "        else: \n",
    "            input_final = input(\"Previsualizar/Guardar: \")\n",
    "            input_final = str(input_final).lower()\n",
    "            hoy = datetime.today().strftime('%Y-%m-%d')\n",
    "            if input_final == 'previsualizar':\n",
    "                print('\\nPrevisualización 6 filas:\\n')\n",
    "                with pd.option_context('display.max_rows', 10, 'display.max_columns', None):\n",
    "                    display(df_final)\n",
    "                input_final = input(\"Guardar finalmente (si/no): \")\n",
    "                input_final = str(input_final).lower()\n",
    "                if input_final == 'si':\n",
    "                    try:\n",
    "                        guardar_excel(df_final, username +'/Saltarina '+hoy+' ('+username+')')        \n",
    "                    except: \n",
    "                        for unidad in ['G:', 'H:', 'W:', 'R:', 'V:', 'Y:', 'H:', 'A:', 'B:', 'C:', 'D:', 'E:', 'F:', 'I:', 'J:', 'K:', 'L:', 'M:', 'N:', 'O:', 'P:', 'Q:', 'S:', 'T:', 'U:', 'X:', 'Z:']: \n",
    "                            if os.path.exists(unidad + '/02_Antifraude/04_PYTHON/Base de datos analisis'):\n",
    "                                os.makedirs(unidad + '/02_Antifraude/04_PYTHON/Base de datos analisis/'+username)\n",
    "                        guardar_excel(df_final, username +'/Saltarina '+hoy+' ('+username+')')               \n",
    "            elif input_final == 'guardar':\n",
    "                try:\n",
    "                    guardar_excel(df_final, username +'/Saltarina '+hoy+' ('+username+')')        \n",
    "                except: \n",
    "                    for unidad in ['G:', 'H:', 'W:', 'R:', 'V:', 'Y:', 'H:', 'A:', 'B:', 'C:', 'D:', 'E:', 'F:', 'I:', 'J:', 'K:', 'L:', 'M:', 'N:', 'O:', 'P:', 'Q:', 'S:', 'T:', 'U:', 'X:', 'Z:']: \n",
    "                        if os.path.exists(unidad + '/02_Antifraude/04_PYTHON/Base de datos analisis'):\n",
    "                            os.makedirs(unidad + '/02_Antifraude/04_PYTHON/Base de datos analisis/'+username)\n",
    "                    guardar_excel(df_final, username +'/Saltarina '+hoy+' ('+username+')')           \n",
    "    else: pass \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f181670-4d4b-4747-b45c-afe85515c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pandasModel(QAbstractTableModel):\n",
    "    def __init__(self, data):\n",
    "        QAbstractTableModel.__init__(self)\n",
    "        self._data = data\n",
    "\n",
    "        # Botón para volver atrás\n",
    "        self.boton_atras = QPushButton('Volver atrás')\n",
    "        def on_atras_clicked():\n",
    "            self.view.close()  # Cierra la vista de la tabla\n",
    "        self.boton_atras.clicked.connect(on_atras_clicked)\n",
    "\n",
    "    def rowCount(self, parent=None):\n",
    "        return min(10, self._data.shape[0])\n",
    "\n",
    "    def columnCount(self, parnet=None):\n",
    "        return self._data.shape[1]\n",
    "\n",
    "    def data(self, index, role=Qt.DisplayRole):\n",
    "        if index.isValid():\n",
    "            if role == Qt.DisplayRole:\n",
    "                return str(self._data.iloc[index.row(), index.column()])\n",
    "        return None\n",
    "\n",
    "    def headerData(self, col, orientation, role):\n",
    "        if orientation == Qt.Horizontal and role == Qt.DisplayRole:\n",
    "            return self._data.columns[col]\n",
    "        return None\n",
    "\n",
    "    def show(self):\n",
    "        self.view = QTableView()\n",
    "        self.view.setModel(self)\n",
    "        self.view.resize(800, 600)\n",
    "        \n",
    "        layout = QVBoxLayout()\n",
    "        # layout.addWidget(self.boton_atras)\n",
    "        layout.addWidget(self.view)\n",
    "        \n",
    "        self.ventana = QWidget()\n",
    "        self.ventana.setLayout(layout)\n",
    "        self.ventana.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1775cd-eef1-492b-bd4b-c32b6e88f70f",
   "metadata": {},
   "source": [
    "Acceso directo de comando en cmd\n",
    "1. Haz clic derecho en tu escritorio.\n",
    "2. Selecciona `Nuevo -> Acceso directo`.\n",
    "3. Luego, ingresa la siguiente ubicación: `C:\\\\Windows\\\\System32\\\\cmd.exe /k cd C:\\\\Users\\\\TU_USUARIO\\\\TU_DIRECTORIO && jupyter notebook`\n",
    "   - Reemplaza `TU_USUARIO` y `TU_DIRECTORIO` con tu nombre de usuario y el directorio donde deseas abrir Jupyter Notebook.\n",
    "4. Haz clic en `Siguiente` y luego puedes darle un nombre a ese acceso directo.\n",
    "5. Finalmente, haz clic en `Finalizar`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31a2dd-a3c7-4633-b5d0-7b2cd329990a",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344f332-b939-44c4-884c-f98da6141b61",
   "metadata": {},
   "source": [
    "#    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b303a3-29f8-4940-9f15-f1c8b767260c",
   "metadata": {},
   "source": [
    "#    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430cf62-cfe1-4c56-ba98-e7c7f2824e56",
   "metadata": {},
   "source": [
    "#    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19514bb7-6e57-44bf-a7bf-4654983731ce",
   "metadata": {},
   "source": [
    "#    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
