{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d609d7e7-b552-420c-9a1e-5a9f63dc761a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Spark DataFrames Project Exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aea4ab44-cf4f-494e-8d29-d38a1af2beb4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's get some quick practice with your new Spark DataFrame skills, you will be asked some basic questions about some stock market data, in this case Walmart Stock from the years 2012-2017. This exercise will just ask a bunch of questions, unlike the future machine learning exercises, which will be a little looser and be in the form of \"Consulting Projects\", but more on that later!\n",
    "\n",
    "For now, just answer the questions and complete the tasks below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b771f78a-88f9-44dd-8d3d-7632c94d36e7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Use the walmart_stock.csv file to Answer and complete the  tasks below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68e53802-5c28-4958-bac7-860ac4ba98d3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Start a simple Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "795124aa-202e-4543-b95f-6ae0f76be7ba",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b35e6ebd-087e-496a-94d2-0187d2e8325f",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "source": [
    "#### Load the Walmart Stock CSV File, have Spark infer the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aab8783-1ccf-442f-8d4e-8aac3d86b7b6",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv('/FileStore/tables/walmart_stock', inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d112c37-f695-435b-b2b2-077237e836d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|\n+----------+------------------+------------------+------------------+------------------+--------+------------------+\n|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|\n|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|\n|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|\n|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|\n|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|\n|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|\n|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|\n|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|\n|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|\n|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|\n|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|\n|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|\n|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996|\n|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|\n|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|\n|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|\n|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|\n|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|\n|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|\n|2012-01-31|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006|\n+----------+------------------+------------------+------------------+------------------+--------+------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61966a65-8bc1-45e1-b055-3551e6d21f51",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### What are the column names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef247737-7a24-463e-a887-14219e344918",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[6]: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e327474d-425a-4161-b97d-e452f036bb85",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### What does the Schema look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "facdc50e-b32d-4ad8-ba9e-228dd867b052",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Date: date (nullable = true)\n |-- Open: double (nullable = true)\n |-- High: double (nullable = true)\n |-- Low: double (nullable = true)\n |-- Close: double (nullable = true)\n |-- Volume: integer (nullable = true)\n |-- Adj Close: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d57561cb-8833-40a3-845e-de373c428d36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d25bb17f-d365-4a68-9c3d-9a6732a7c824",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Print out the first 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc4ad44b-17ea-48e1-8364-f207b6e75134",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[10]: [Row(Date=datetime.date(2012, 1, 3), Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996),\n Row(Date=datetime.date(2012, 1, 4), Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475),\n Row(Date=datetime.date(2012, 1, 5), Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539),\n Row(Date=datetime.date(2012, 1, 6), Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922),\n Row(Date=datetime.date(2012, 1, 9), Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004)]"
     ]
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf2a2c61-f858-47a8-be5e-9ec0912651e8",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|\n+----------+------------------+------------------+------------------+------------------+--------+------------------+\n|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|\n|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|\n|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|\n|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|\n|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|\n|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|\n|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|\n|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|\n|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|\n|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|\n+----------+------------------+------------------+------------------+------------------+--------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "307e62b7-f5f5-41ac-ad35-231477331fcb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Use describe() to learn about the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63cb79a7-8df7-440a-9964-6cbf3d6da459",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "265243e7-8b26-4f80-8e6d-c27d04fa959c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Bonus Question!\n",
    "#### There are too many decimal places for mean and stddev in the describe() dataframe. Format the numbers to just show up to two decimal places. Pay careful attention to the datatypes that .describe() returns, we didn't cover how to do this exact formatting, but we covered something very similar. [Check this link for a hint](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Column.cast)\n",
    "\n",
    "If you get stuck on this, don't worry, just view the solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bad142b7-c92c-49e6-95e4-c3f036491c08",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+------+------+----------+---------+\n|summary|Open  |High  |Low   |Close |Volume    |Adj Close|\n+-------+------+------+------+------+----------+---------+\n|count  |1258.0|1258.0|1258.0|1258.0|1258.0    |1258.0   |\n|mean   |72.36 |72.84 |71.92 |72.39 |8222093.48|67.24    |\n|stddev |6.77  |6.77  |6.74  |6.76  |4519780.84|6.72     |\n|min    |56.39 |57.06 |56.3  |56.42 |2094900.0 |50.36    |\n|max    |90.8  |90.97 |89.25 |90.47 |8.08981E7 |84.91    |\n+-------+------+------+------+------+----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, round, concat, lit\n",
    "\n",
    "df1 = df.describe()\n",
    "columns = df1.columns\n",
    "columns.remove('summary')\n",
    "summary = df1.select(\"summary\")\n",
    "df1_rounded = df1.select(\"summary\", *[round(df1[c].cast(\"double\"), 2).alias(c) for c in columns])\n",
    "df1_rounded.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "484b6d7b-8be8-4d32-a55b-0514ff23b795",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+--------+--------+\n|summary|    Open|    High|     Low|   Close|  Volume|\n+-------+--------+--------+--------+--------+--------+\n|  count|1,258.00|1,258.00|1,258.00|1,258.00|    1258|\n|   mean|   72.36|   72.84|   71.92|   72.39| 8222093|\n| stddev|    6.77|    6.77|    6.74|    6.76| 4519781|\n|    min|   56.39|   57.06|   56.30|   56.42| 2094900|\n|    max|   90.80|   90.97|   89.25|   90.47|80898100|\n+-------+--------+--------+--------+--------+--------+\n\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dcc5359-398f-4e44-a735-67c394f0aa37",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Create a new dataframe with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcba852d-4d95-4cc8-869d-69a2c5abb04d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n|            HV Ratio|\n+--------------------+\n|4.819714653321546E-6|\n|6.290848613094555E-6|\n|4.669412994783916E-6|\n|7.367338463826307E-6|\n|8.915604778943901E-6|\n|8.644477436914568E-6|\n|9.351828421515645E-6|\n| 8.29141562102703E-6|\n|7.712212102001476E-6|\n|7.071764823529412E-6|\n|1.015495466386981E-5|\n|6.576354146362592...|\n| 5.90145296180676E-6|\n|8.547679455011844E-6|\n|8.420709512685392E-6|\n|1.041448341728929...|\n|8.316075414862431E-6|\n|9.721183814992126E-6|\n|8.029436027707578E-6|\n|6.307432259386365E-6|\n+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df1 = df.withColumn('HV Ratio',(df.High/df.Volume)).select(\"HV Ratio\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7e14816-7f7c-471d-9b79-d97961ebb66c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### What day had the Peak High in Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b9d4288-bc84-4747-922d-3ec0c266dd74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[48]: datetime.date(2012, 1, 3)"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean,max\n",
    "df.agg({\"Date\":\"First\",\"High\": \"max\"}).collect()[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d42b3e4-0106-4059-9255-88f70eb5385d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### What is the mean of the Close column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de0325e6-5d1e-4aee-b04d-33911654dc66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n|       avg(Close)|\n+-----------------+\n|72.38844998012726|\n+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.agg({\"Close\": \"mean\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdc4bb31-2031-487f-8bb2-67b1d0241bad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### What is the max and min of the Volume column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "869e7c9b-793a-4539-a104-dea30334aa7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max, min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b70a138e-2ba5-448a-a7df-fc17f3cf97ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n|max(Volume)|min(Volume)|\n+-----------+-----------+\n|   80898100|    2094900|\n+-----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "df.agg(\n",
    "    max(\"Volume\"), \n",
    "    min(\"Volume\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fa3a04f-bd4a-433d-b19c-329baffdbf30",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### How many days was the Close lower than 60 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f84a0bbf-ae8a-468a-8404-b76f5a7cf612",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n|count(Date)|\n+-----------+\n|         81|\n+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "df.filter(\"Close < 60\").select(count(\"Date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "188a9ab9-cfd9-4f79-896d-f8855c482009",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[89]: 81"
     ]
    }
   ],
   "source": [
    "df.filter(\"Close < 60\").agg(count(\"Date\").alias(\"count\")).collect()[0][\"count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee93b6f9-ccb7-4842-a231-24c01d5ec86f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### What percentage of the time was the High greater than 80 dollars ?\n",
    "#### In other words, (Number of Days High>80)/(Total Days in the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60657ed9-8b04-4341-be6d-103dd0d7fda0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[91]: 9.141494435612083"
     ]
    }
   ],
   "source": [
    "df.filter(\"High > 80\").agg(count(\"Date\").alias(\"count\")).collect()[0][\"count\"] / df.agg(count(\"Date\").alias(\"count\")).collect()[0][\"count\"] *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f577b22-4e74-44c7-8f31-3e68e61f12a2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### What is the Pearson correlation between High and Volume?\n",
    "#### [Hint](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameStatFunctions.corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b5ad752-97df-4890-9e50-ef5570b6bcab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[98]: -0.3384326061737161"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import DenseMatrix, Vectors\n",
    "from pyspark.ml.stat import Correlation\n",
    "df.stat.corr('High', 'Volume')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "664e10e7-a950-46ba-aaa3-fb932b4c2e6e",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n| corr(High, Volume)|\n+-------------------+\n|-0.3384326061737161|\n+-------------------+\n\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64d8ebc3-a1f1-4cbe-92e4-624d282af7af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### What is the max High per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69fe054b-fd04-435c-8fce-f21cedf4d4ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n|Year|max(High)|\n+----+---------+\n|2012|   $77.60|\n|2013|   $81.37|\n|2014|   $88.09|\n|2015|   $90.97|\n|2016|   $75.19|\n+----+---------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import hour,dayofyear,dayofmonth,hour,month,year,weekofyear,date_format,format_number, concat, lit\n",
    "df = df.withColumn('Year',year(df.Date))\n",
    "df.groupBy('Year').max('High').orderBy('Year').withColumn('max(High)', concat(lit('$'),format_number('max(High)', 2))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa60041f-0d57-40da-8638-0c464ed72cf2",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n|Year|max(High)|\n+----+---------+\n|2015|90.970001|\n|2013|81.370003|\n|2014|88.089996|\n|2012|77.599998|\n|2016|75.190002|\n+----+---------+\n\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d924175b-c956-4c17-9040-2048c4555974",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### What is the average Close for each Calendar Month?\n",
    "#### In other words, across all the years, what is the average Close price for Jan,Feb, Mar, etc... Your result will have a value for each of these months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f70d52db-0e82-49e3-adca-e3249e3e3ed2",
     "showTitle": false,
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n|Month|avg(Close)|\n+-----+----------+\n|    1|    $71.45|\n|    2|    $71.31|\n|    3|    $71.78|\n|    4|    $72.97|\n|    5|    $72.31|\n|    6|    $72.50|\n|    7|    $74.44|\n|    8|    $73.03|\n|    9|    $72.18|\n|   10|    $71.58|\n|   11|    $72.11|\n|   12|    $72.85|\n+-----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('Month',month(df.Date))\n",
    "df.groupBy('Month').avg('Close').orderBy('Month').withColumn('avg(Close)', concat(lit('$'),format_number('avg(Close)', 2))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "751dadc4-2f4b-4332-8670-35abc0d6eb83",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark DataFrames Project Exercise",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
